{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvise a Jazz Solo with an LSTM Network\n",
    "\n",
    "Welcome to your final programming assignment of this week! In this notebook, you will implement a model that uses an LSTM to generate music. You will even be able to listen to your own music at the end of the assignment. \n",
    "\n",
    "**You will learn to:**\n",
    "- Apply an LSTM to music generation.\n",
    "- Generate your own jazz music with deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Updates</font>\n",
    "\n",
    "#### If you were working on the notebook before this update...\n",
    "* The current notebook is version \"3a\".\n",
    "* You can find your original work saved in the notebook with the previous version name (\"v3\") \n",
    "* To view the file directory, go to the menu \"File->Open\", and this will open a new tab that shows the file directory.\n",
    "\n",
    "#### List of updates\n",
    "* `djmodel`\n",
    "    - Explains `Input` layer and its parameter `shape`.\n",
    "    - Explains `Lambda` layer and replaces the given solution with hints and sample code (to improve the learning experience).\n",
    "    - Adds hints for using the Keras `Model`.\n",
    "* `music_inference_model`\n",
    "    - Explains each line of code in the `one_hot` function.\n",
    "    - Explains how to apply `one_hot` with a Lambda layer instead of giving the code solution (to improve the learning experience).\n",
    "    - Adds instructions on defining the `Model`.\n",
    "* `predict_and_sample`\n",
    "    - Provides detailed instructions for each step.\n",
    "    - Clarifies which variable/function to use for inference.\n",
    "* Spelling, grammar and wording corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell to load all the packages required in this assignment. This may take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Problem statement\n",
    "\n",
    "You would like to create a jazz music piece specially for a friend's birthday. However, you don't know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM network.  \n",
    "\n",
    "You will train a network to generate novel jazz solos in a style representative of a body of performed work.\n",
    "\n",
    "<img src=\"images/jazz.jpg\" style=\"width:450;height:300px;\">\n",
    "\n",
    "\n",
    "### 1.1 - Dataset\n",
    "\n",
    "You will train your algorithm on a corpus of Jazz music. Run the cell below to listen to a snippet of the audio from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_seq.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken care of the preprocessing of the musical data to render it in terms of musical \"values.\" \n",
    "\n",
    "#### Details about music (optional)\n",
    "You can informally think of each \"value\" as a note, which comprises a pitch and duration. For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a \"value\" is actually more complicated than this--specifically, it also captures the information needed to play multiple notes at the same time. For example, when playing a music piece, you might press down two piano keys at the same time (playing multiple notes at the same time generates what's called a \"chord\"). But we don't need to worry about the details of music theory for this assignment. \n",
    "\n",
    "#### Music as a sequence of values\n",
    "* For the purpose of this assignment, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. \n",
    "* Our music generation system will use 78 unique values. \n",
    "\n",
    "Run the following code to load the raw music data and preprocess it into values. This might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 60\n",
      "Tx (length of sequence): 30\n",
      "total # of unique values: 78\n",
      "shape of X: (60, 30, 78)\n",
      "Shape of Y: (30, 60, 78)\n"
     ]
    }
   ],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('shape of X:', X.shape)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have just loaded the following:\n",
    "\n",
    "- `X`: This is an (m, $T_x$, 78) dimensional array. \n",
    "    - We have m training examples, each of which is a snippet of $T_x =30$ musical values. \n",
    "    - At each time step, the input is one of 78 different possible values, represented as a one-hot vector. \n",
    "        - For example, X[i,t,:] is a one-hot vector representing the value of the i-th example at time t. \n",
    "\n",
    "- `Y`: a $(T_y, m, 78)$ dimensional array\n",
    "    - This is essentially the same as `X`, but shifted one step to the left (to the past). \n",
    "    - Notice that the data in `Y` is **reordered** to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed into the LSTM later.\n",
    "    - Similar to the dinosaur assignment, we're using the previous values to predict the next value.\n",
    "        - So our sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$. \n",
    "\n",
    "- `n_values`: The number of unique values in this dataset. This should be 78. \n",
    "\n",
    "- `indices_values`: python dictionary mapping integers 0 through 77 to musical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of our model\n",
    "\n",
    "Here is the architecture of the model we will use. This is similar to the Dinosaurus model, except that you will implement it in Keras.\n",
    "\n",
    "<img src=\"images/music_generation.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "\n",
    "* $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\cdots, x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the musical corpus. \n",
    "* Each $x^{\\langle t \\rangle}$ is an index corresponding to a value.\n",
    "* $\\hat{y}^{t}$ is the prediction for the next value.\n",
    "* We will be training the model on random snippets of 30 values taken from a much longer piece of music. \n",
    "    - Thus, we won't bother to set the first input $x^{\\langle 1 \\rangle} = \\vec{0}$, since most of these snippets of audio start somewhere in the middle of a piece of music. \n",
    "    - We are setting each of the snippets to have the same length $T_x = 30$ to make vectorization easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of parts 2 and 3\n",
    "\n",
    "* We're going to train a model that predicts the next note in a style that is similar to the jazz music that it's trained on.  The training is contained in the weights and biases of the model. \n",
    "* In Part 3, we're then going to use those weights and biases in a new model which predicts a series of notes, using the previous note to predict the next note. \n",
    "* The weights and biases are transferred to the new model using 'global shared layers' described below\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building the model\n",
    "\n",
    "* In this part you will build and train a model that will learn musical patterns. \n",
    "* The model takes input X of shape $(m, T_x, 78)$ and labels Y of shape $(T_y, m, 78)$. \n",
    "* We will use an LSTM with hidden states that have $n_{a} = 64$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of dimensions for the hidden state of each LSTM cell.\n",
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Sequence generation uses a for-loop\n",
    "* If you're building an RNN where, at test time, the entire input sequence $x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle T_x \\rangle}$ is given in advance, then Keras has simple built-in functions to build the model. \n",
    "* However, for **sequence generation, at test time we don't know all the values of $x^{\\langle t\\rangle}$ in advance**.\n",
    "* Instead we generate them one at a time using $x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$. \n",
    "    * The input at time \"t\" is the prediction at the previous time step \"t-1\".\n",
    "* So you'll need to implement your own for-loop to iterate over the time steps. \n",
    "\n",
    "#### Shareable weights\n",
    "* The function `djmodel()` will call the LSTM layer $T_x$ times using a for-loop.\n",
    "* It is important that all $T_x$ copies have the same weights. \n",
    "    - The $T_x$ steps should have shared weights that aren't re-initialized.\n",
    "* Referencing a globally defined shared layer will utilize the same layer-object instance at each time step.\n",
    "* The key steps for implementing layers with shareable weights in Keras are: \n",
    "1. Define the layer objects (we will use global variables for this).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "#### 3 types of layers\n",
    "* We have defined the layers objects you need as global variables.  \n",
    "* Please run the next cell to create them. \n",
    "* Please read the Keras documentation and understand these layers: \n",
    "    - [Reshape()](https://keras.io/layers/core/#reshape): Reshapes an output to a certain shape.\n",
    "    - [LSTM()](https://keras.io/layers/recurrent/#lstm): Long Short-Term Memory layer\n",
    "    - [Dense()](https://keras.io/layers/core/#dense): A regular fully-connected neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_values = 78 # number of music values\n",
    "reshapor = Reshape((1, n_values))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `reshapor`, `LSTM_cell` and `densor` are globally defined layer objects, that you'll use to implement `djmodel()`. \n",
    "* In order to propagate a Keras tensor object X through one of these layers, use `layer_object()`.\n",
    "    - For one input, use `layer_object(X)`\n",
    "    - For more than one input, put the inputs in a list: `layer_object([X1,X2])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Exercise**: Implement `djmodel()`. \n",
    "\n",
    "#### Inputs (given)\n",
    "* The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "* The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "    - For example,\n",
    "    ```Python\n",
    "    X = Input(shape=(Tx, n_values)) # X has 3 dimensions and not 2: (m, Tx, n_values)\n",
    "    ```\n",
    "#### Step 1: Outputs (TODO)\n",
    "1. Create an empty list \"outputs\" to save the outputs of the LSTM Cell at every time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Loop through time steps (TODO)\n",
    "* Loop for $t \\in 1, \\ldots, T_x$:\n",
    "\n",
    "#### 2A. Select the 't' time-step vector from X.\n",
    "* X has the shape (m, Tx, n_values).\n",
    "* The shape of the 't' selection should be (n_values,). \n",
    "* Recall that if you were implementing in numpy instead of Keras, you would extract a slice from a 3D numpy array like this:\n",
    "```Python\n",
    "var1 = array1[:,1,:]\n",
    "```\n",
    "    \n",
    "#### Lambda layer\n",
    "* Since we're using Keras, we need to define this step inside a custom layer.\n",
    "* In Keras, this is a Lambda layer [Lambda](https://keras.io/layers/core/#lambda)\n",
    "* As an example, a Lambda layer that takes the previous layer and adds '1' looks like this\n",
    "```    \n",
    "       lambda_layer1 = Lambda(lambda z: z + 1)(previous_layer)\n",
    "``` \n",
    "* The previous layer in this case is `X`.\n",
    "* `z` is a local variable of the lambda function. \n",
    "    * The `previous_layer` gets passed into the parameter `z` in the lowercase `lambda` function.\n",
    "    * You can choose the name of the variable to be something else if you want.\n",
    "* The operation after the colon ':' should be the operation to extract a slice from the previous layer.\n",
    "* **Hint**: You'll be using the variable `t` within the definition of the lambda layer even though it isn't passed in as an argument to Lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2B. Reshape x to be (1,n_values).\n",
    "* Use the `reshapor()` layer.  It is a function that takes the previous layer as its input argument.\n",
    "\n",
    "#### 2C. Run x through one step of LSTM_cell.\n",
    "* Initialize the `LSTM_cell` with the previous step's hidden state $a$ and cell state $c$. \n",
    "* Use the following formatting:\n",
    "```python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(inputs=input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "    * Choose appropriate variables for inputs, hidden state and cell state.\n",
    "\n",
    "#### 2D. Dense layer\n",
    "* Propagate the LSTM's hidden state through a dense+softmax layer using `densor`. \n",
    "    \n",
    "#### 2E. Append output\n",
    "* Append the output to the list of \"outputs\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: After the loop, create the model\n",
    "* Use the Keras `Model` object to create a model.\n",
    "* specify the inputs and outputs:\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "    * Choose the appropriate variables for the input tensor, hidden state, cell state, and output.\n",
    "* See the documentation for [Model](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras instance model with n_a activations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input layer and specify the shape\n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define the initial hidden state a0 and initial cell state c0\n",
    "    # using `Input`\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x: X[:,t,:])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model object\n",
    "* Run the following cell to define your model. \n",
    "* We will use `Tx=30`, `n_a=64` (the dimension of the LSTM activations), and `n_values=78`. \n",
    "* This cell may take a few seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 30, 78)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 78)         0           lambda_31[0][0]                  \n",
      "                                                                   lambda_32[0][0]                  \n",
      "                                                                   lambda_33[0][0]                  \n",
      "                                                                   lambda_34[0][0]                  \n",
      "                                                                   lambda_35[0][0]                  \n",
      "                                                                   lambda_36[0][0]                  \n",
      "                                                                   lambda_37[0][0]                  \n",
      "                                                                   lambda_38[0][0]                  \n",
      "                                                                   lambda_39[0][0]                  \n",
      "                                                                   lambda_40[0][0]                  \n",
      "                                                                   lambda_41[0][0]                  \n",
      "                                                                   lambda_42[0][0]                  \n",
      "                                                                   lambda_43[0][0]                  \n",
      "                                                                   lambda_44[0][0]                  \n",
      "                                                                   lambda_45[0][0]                  \n",
      "                                                                   lambda_46[0][0]                  \n",
      "                                                                   lambda_47[0][0]                  \n",
      "                                                                   lambda_48[0][0]                  \n",
      "                                                                   lambda_49[0][0]                  \n",
      "                                                                   lambda_50[0][0]                  \n",
      "                                                                   lambda_51[0][0]                  \n",
      "                                                                   lambda_52[0][0]                  \n",
      "                                                                   lambda_53[0][0]                  \n",
      "                                                                   lambda_54[0][0]                  \n",
      "                                                                   lambda_55[0][0]                  \n",
      "                                                                   lambda_56[0][0]                  \n",
      "                                                                   lambda_57[0][0]                  \n",
      "                                                                   lambda_58[0][0]                  \n",
      "                                                                   lambda_59[0][0]                  \n",
      "                                                                   lambda_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "a0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 64), (None, 6 36608       reshape_1[30][0]                 \n",
      "                                                                   a0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   reshape_1[31][0]                 \n",
      "                                                                   lstm_1[30][0]                    \n",
      "                                                                   lstm_1[30][2]                    \n",
      "                                                                   reshape_1[32][0]                 \n",
      "                                                                   lstm_1[31][0]                    \n",
      "                                                                   lstm_1[31][2]                    \n",
      "                                                                   reshape_1[33][0]                 \n",
      "                                                                   lstm_1[32][0]                    \n",
      "                                                                   lstm_1[32][2]                    \n",
      "                                                                   reshape_1[34][0]                 \n",
      "                                                                   lstm_1[33][0]                    \n",
      "                                                                   lstm_1[33][2]                    \n",
      "                                                                   reshape_1[35][0]                 \n",
      "                                                                   lstm_1[34][0]                    \n",
      "                                                                   lstm_1[34][2]                    \n",
      "                                                                   reshape_1[36][0]                 \n",
      "                                                                   lstm_1[35][0]                    \n",
      "                                                                   lstm_1[35][2]                    \n",
      "                                                                   reshape_1[37][0]                 \n",
      "                                                                   lstm_1[36][0]                    \n",
      "                                                                   lstm_1[36][2]                    \n",
      "                                                                   reshape_1[38][0]                 \n",
      "                                                                   lstm_1[37][0]                    \n",
      "                                                                   lstm_1[37][2]                    \n",
      "                                                                   reshape_1[39][0]                 \n",
      "                                                                   lstm_1[38][0]                    \n",
      "                                                                   lstm_1[38][2]                    \n",
      "                                                                   reshape_1[40][0]                 \n",
      "                                                                   lstm_1[39][0]                    \n",
      "                                                                   lstm_1[39][2]                    \n",
      "                                                                   reshape_1[41][0]                 \n",
      "                                                                   lstm_1[40][0]                    \n",
      "                                                                   lstm_1[40][2]                    \n",
      "                                                                   reshape_1[42][0]                 \n",
      "                                                                   lstm_1[41][0]                    \n",
      "                                                                   lstm_1[41][2]                    \n",
      "                                                                   reshape_1[43][0]                 \n",
      "                                                                   lstm_1[42][0]                    \n",
      "                                                                   lstm_1[42][2]                    \n",
      "                                                                   reshape_1[44][0]                 \n",
      "                                                                   lstm_1[43][0]                    \n",
      "                                                                   lstm_1[43][2]                    \n",
      "                                                                   reshape_1[45][0]                 \n",
      "                                                                   lstm_1[44][0]                    \n",
      "                                                                   lstm_1[44][2]                    \n",
      "                                                                   reshape_1[46][0]                 \n",
      "                                                                   lstm_1[45][0]                    \n",
      "                                                                   lstm_1[45][2]                    \n",
      "                                                                   reshape_1[47][0]                 \n",
      "                                                                   lstm_1[46][0]                    \n",
      "                                                                   lstm_1[46][2]                    \n",
      "                                                                   reshape_1[48][0]                 \n",
      "                                                                   lstm_1[47][0]                    \n",
      "                                                                   lstm_1[47][2]                    \n",
      "                                                                   reshape_1[49][0]                 \n",
      "                                                                   lstm_1[48][0]                    \n",
      "                                                                   lstm_1[48][2]                    \n",
      "                                                                   reshape_1[50][0]                 \n",
      "                                                                   lstm_1[49][0]                    \n",
      "                                                                   lstm_1[49][2]                    \n",
      "                                                                   reshape_1[51][0]                 \n",
      "                                                                   lstm_1[50][0]                    \n",
      "                                                                   lstm_1[50][2]                    \n",
      "                                                                   reshape_1[52][0]                 \n",
      "                                                                   lstm_1[51][0]                    \n",
      "                                                                   lstm_1[51][2]                    \n",
      "                                                                   reshape_1[53][0]                 \n",
      "                                                                   lstm_1[52][0]                    \n",
      "                                                                   lstm_1[52][2]                    \n",
      "                                                                   reshape_1[54][0]                 \n",
      "                                                                   lstm_1[53][0]                    \n",
      "                                                                   lstm_1[53][2]                    \n",
      "                                                                   reshape_1[55][0]                 \n",
      "                                                                   lstm_1[54][0]                    \n",
      "                                                                   lstm_1[54][2]                    \n",
      "                                                                   reshape_1[56][0]                 \n",
      "                                                                   lstm_1[55][0]                    \n",
      "                                                                   lstm_1[55][2]                    \n",
      "                                                                   reshape_1[57][0]                 \n",
      "                                                                   lstm_1[56][0]                    \n",
      "                                                                   lstm_1[56][2]                    \n",
      "                                                                   reshape_1[58][0]                 \n",
      "                                                                   lstm_1[57][0]                    \n",
      "                                                                   lstm_1[57][2]                    \n",
      "                                                                   reshape_1[59][0]                 \n",
      "                                                                   lstm_1[58][0]                    \n",
      "                                                                   lstm_1[58][2]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)               (None, 78)            0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 78)            5070        lstm_1[30][0]                    \n",
      "                                                                   lstm_1[31][0]                    \n",
      "                                                                   lstm_1[32][0]                    \n",
      "                                                                   lstm_1[33][0]                    \n",
      "                                                                   lstm_1[34][0]                    \n",
      "                                                                   lstm_1[35][0]                    \n",
      "                                                                   lstm_1[36][0]                    \n",
      "                                                                   lstm_1[37][0]                    \n",
      "                                                                   lstm_1[38][0]                    \n",
      "                                                                   lstm_1[39][0]                    \n",
      "                                                                   lstm_1[40][0]                    \n",
      "                                                                   lstm_1[41][0]                    \n",
      "                                                                   lstm_1[42][0]                    \n",
      "                                                                   lstm_1[43][0]                    \n",
      "                                                                   lstm_1[44][0]                    \n",
      "                                                                   lstm_1[45][0]                    \n",
      "                                                                   lstm_1[46][0]                    \n",
      "                                                                   lstm_1[47][0]                    \n",
      "                                                                   lstm_1[48][0]                    \n",
      "                                                                   lstm_1[49][0]                    \n",
      "                                                                   lstm_1[50][0]                    \n",
      "                                                                   lstm_1[51][0]                    \n",
      "                                                                   lstm_1[52][0]                    \n",
      "                                                                   lstm_1[53][0]                    \n",
      "                                                                   lstm_1[54][0]                    \n",
      "                                                                   lstm_1[55][0]                    \n",
      "                                                                   lstm_1[56][0]                    \n",
      "                                                                   lstm_1[57][0]                    \n",
      "                                                                   lstm_1[58][0]                    \n",
      "                                                                   lstm_1[59][0]                    \n",
      "====================================================================================================\n",
      "Total params: 41,678\n",
      "Trainable params: 41,678\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "Scroll to the bottom of the output, and you'll see the following:\n",
    "\n",
    "```Python\n",
    "Total params: 41,678\n",
    "Trainable params: 41,678\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training\n",
    "* You now need to compile your model to be trained. \n",
    "* We will use:\n",
    "    - optimizer: Adam optimizer\n",
    "    - Loss function: categorical cross-entropy (for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize hidden state and cell state\n",
    "Finally, let's initialize `a0` and `c0` for the LSTM's initial state to be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "* Lets now fit the model! \n",
    "* We will turn `Y` into a list, since the cost function expects `Y` to be provided in this format \n",
    "    - `list(Y)` is a list with 30 items, where each of the list items is of shape (60,78). \n",
    "    - Lets train for 100 epochs. This will take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 3s - loss: 125.9214 - dense_1_loss_1: 4.3547 - dense_1_loss_2: 4.3505 - dense_1_loss_3: 4.3415 - dense_1_loss_4: 4.3464 - dense_1_loss_5: 4.3462 - dense_1_loss_6: 4.3473 - dense_1_loss_7: 4.3449 - dense_1_loss_8: 4.3466 - dense_1_loss_9: 4.3449 - dense_1_loss_10: 4.3403 - dense_1_loss_11: 4.3414 - dense_1_loss_12: 4.3412 - dense_1_loss_13: 4.3441 - dense_1_loss_14: 4.3320 - dense_1_loss_15: 4.3370 - dense_1_loss_16: 4.3407 - dense_1_loss_17: 4.3402 - dense_1_loss_18: 4.3363 - dense_1_loss_19: 4.3353 - dense_1_loss_20: 4.3438 - dense_1_loss_21: 4.3436 - dense_1_loss_22: 4.3351 - dense_1_loss_23: 4.3474 - dense_1_loss_24: 4.3391 - dense_1_loss_25: 4.3410 - dense_1_loss_26: 4.3394 - dense_1_loss_27: 4.3421 - dense_1_loss_28: 4.3445 - dense_1_loss_29: 4.3340 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0000e+00 - dense_1_acc_2: 0.0000e+00 - dense_1_acc_3: 0.0500 - dense_1_acc_4: 0.0333 - dense_1_acc_5: 0.0333 - dense_1_acc_6: 0.0667 - dense_1_acc_7: 0.0167 - dense_1_acc_8: 0.0333 - dense_1_acc_9: 0.0333 - dense_1_acc_10: 0.0167 - dense_1_acc_11: 0.0667 - dense_1_acc_12: 0.0333 - dense_1_acc_13: 0.0667 - dense_1_acc_14: 0.0667 - dense_1_acc_15: 0.0333 - dense_1_acc_16: 0.0167 - dense_1_acc_17: 0.0333 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.0500 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0167 - dense_1_acc_22: 0.0833 - dense_1_acc_23: 0.0167 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.0333 - dense_1_acc_26: 0.0167 - dense_1_acc_27: 0.0333 - dense_1_acc_28: 0.0500 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0500                                                                                                             \n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s - loss: 122.7694 - dense_1_loss_1: 4.3327 - dense_1_loss_2: 4.3076 - dense_1_loss_3: 4.2764 - dense_1_loss_4: 4.2763 - dense_1_loss_5: 4.2547 - dense_1_loss_6: 4.2662 - dense_1_loss_7: 4.2536 - dense_1_loss_8: 4.2358 - dense_1_loss_9: 4.2406 - dense_1_loss_10: 4.2244 - dense_1_loss_11: 4.2195 - dense_1_loss_12: 4.2396 - dense_1_loss_13: 4.2159 - dense_1_loss_14: 4.2036 - dense_1_loss_15: 4.2000 - dense_1_loss_16: 4.2108 - dense_1_loss_17: 4.2070 - dense_1_loss_18: 4.2169 - dense_1_loss_19: 4.2015 - dense_1_loss_20: 4.2375 - dense_1_loss_21: 4.2257 - dense_1_loss_22: 4.2007 - dense_1_loss_23: 4.2251 - dense_1_loss_24: 4.2329 - dense_1_loss_25: 4.2224 - dense_1_loss_26: 4.1906 - dense_1_loss_27: 4.2215 - dense_1_loss_28: 4.2112 - dense_1_loss_29: 4.2188 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.1833 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.1167 - dense_1_acc_10: 0.0667 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.1000 - dense_1_acc_16: 0.1000 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.0833 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.1000 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0333 - dense_1_acc_25: 0.0833 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s - loss: 117.2321 - dense_1_loss_1: 4.3111 - dense_1_loss_2: 4.2578 - dense_1_loss_3: 4.1912 - dense_1_loss_4: 4.1745 - dense_1_loss_5: 4.1249 - dense_1_loss_6: 4.1582 - dense_1_loss_7: 4.1067 - dense_1_loss_8: 4.0348 - dense_1_loss_9: 4.0111 - dense_1_loss_10: 3.9157 - dense_1_loss_11: 3.9203 - dense_1_loss_12: 4.0794 - dense_1_loss_13: 3.9346 - dense_1_loss_14: 3.8619 - dense_1_loss_15: 3.9532 - dense_1_loss_16: 3.9693 - dense_1_loss_17: 3.9662 - dense_1_loss_18: 4.0338 - dense_1_loss_19: 3.8893 - dense_1_loss_20: 4.1188 - dense_1_loss_21: 4.0789 - dense_1_loss_22: 3.9725 - dense_1_loss_23: 3.9778 - dense_1_loss_24: 4.0867 - dense_1_loss_25: 4.1490 - dense_1_loss_26: 3.7981 - dense_1_loss_27: 4.0187 - dense_1_loss_28: 3.9664 - dense_1_loss_29: 4.1712 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.1667 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.0667 - dense_1_acc_7: 0.0667 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.0833 - dense_1_acc_10: 0.0333 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0833 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.0833 - dense_1_acc_15: 0.0833 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.0667 - dense_1_acc_20: 0.0000e+00 - dense_1_acc_21: 0.0500 - dense_1_acc_22: 0.1167 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.0333 - dense_1_acc_25: 0.0500 - dense_1_acc_26: 0.0667 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.0833 - dense_1_acc_29: 0.0167 - dense_1_acc_30: 0.0000e+00             \n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s - loss: 112.5845 - dense_1_loss_1: 4.2894 - dense_1_loss_2: 4.2072 - dense_1_loss_3: 4.1025 - dense_1_loss_4: 4.0833 - dense_1_loss_5: 3.9921 - dense_1_loss_6: 4.0168 - dense_1_loss_7: 3.9554 - dense_1_loss_8: 3.7889 - dense_1_loss_9: 3.8150 - dense_1_loss_10: 3.6823 - dense_1_loss_11: 3.7635 - dense_1_loss_12: 3.9750 - dense_1_loss_13: 3.7595 - dense_1_loss_14: 3.7192 - dense_1_loss_15: 3.7471 - dense_1_loss_16: 3.7604 - dense_1_loss_17: 3.8283 - dense_1_loss_18: 3.8221 - dense_1_loss_19: 3.7144 - dense_1_loss_20: 4.0125 - dense_1_loss_21: 3.9994 - dense_1_loss_22: 3.8688 - dense_1_loss_23: 3.8672 - dense_1_loss_24: 3.7714 - dense_1_loss_25: 3.9342 - dense_1_loss_26: 3.5895 - dense_1_loss_27: 3.7338 - dense_1_loss_28: 3.8421 - dense_1_loss_29: 3.9431 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1000 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.1167 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1167 - dense_1_acc_15: 0.0667 - dense_1_acc_16: 0.1000 - dense_1_acc_17: 0.1167 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.1167 - dense_1_acc_20: 0.1167 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.0833 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.2167 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1000 - dense_1_acc_29: 0.1500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s - loss: 109.7018 - dense_1_loss_1: 4.2721 - dense_1_loss_2: 4.1618 - dense_1_loss_3: 4.0396 - dense_1_loss_4: 4.0158 - dense_1_loss_5: 3.9052 - dense_1_loss_6: 3.9184 - dense_1_loss_7: 3.8896 - dense_1_loss_8: 3.7150 - dense_1_loss_9: 3.7350 - dense_1_loss_10: 3.5774 - dense_1_loss_11: 3.6604 - dense_1_loss_12: 3.8751 - dense_1_loss_13: 3.6402 - dense_1_loss_14: 3.5888 - dense_1_loss_15: 3.6729 - dense_1_loss_16: 3.6311 - dense_1_loss_17: 3.7096 - dense_1_loss_18: 3.7456 - dense_1_loss_19: 3.5811 - dense_1_loss_20: 3.7919 - dense_1_loss_21: 3.8312 - dense_1_loss_22: 3.7014 - dense_1_loss_23: 3.6913 - dense_1_loss_24: 3.6391 - dense_1_loss_25: 3.8622 - dense_1_loss_26: 3.5176 - dense_1_loss_27: 3.6897 - dense_1_loss_28: 3.7690 - dense_1_loss_29: 3.8738 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.1000 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.1500 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0333 - dense_1_acc_13: 0.1167 - dense_1_acc_14: 0.1000 - dense_1_acc_15: 0.0833 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1333 - dense_1_acc_18: 0.0333 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0500 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0833 - dense_1_acc_25: 0.0167 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0667 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00             \n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s - loss: 106.9999 - dense_1_loss_1: 4.2566 - dense_1_loss_2: 4.1229 - dense_1_loss_3: 3.9716 - dense_1_loss_4: 3.9480 - dense_1_loss_5: 3.8257 - dense_1_loss_6: 3.8168 - dense_1_loss_7: 3.7953 - dense_1_loss_8: 3.6140 - dense_1_loss_9: 3.6801 - dense_1_loss_10: 3.5204 - dense_1_loss_11: 3.6385 - dense_1_loss_12: 3.7746 - dense_1_loss_13: 3.5543 - dense_1_loss_14: 3.4863 - dense_1_loss_15: 3.6055 - dense_1_loss_16: 3.5016 - dense_1_loss_17: 3.6352 - dense_1_loss_18: 3.6051 - dense_1_loss_19: 3.5083 - dense_1_loss_20: 3.6885 - dense_1_loss_21: 3.7359 - dense_1_loss_22: 3.6305 - dense_1_loss_23: 3.6737 - dense_1_loss_24: 3.5177 - dense_1_loss_25: 3.7500 - dense_1_loss_26: 3.3636 - dense_1_loss_27: 3.5029 - dense_1_loss_28: 3.6458 - dense_1_loss_29: 3.6305 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.1333 - dense_1_acc_9: 0.1500 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.1167 - dense_1_acc_12: 0.0833 - dense_1_acc_13: 0.0500 - dense_1_acc_14: 0.1667 - dense_1_acc_15: 0.1000 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.1167 - dense_1_acc_20: 0.1333 - dense_1_acc_21: 0.1333 - dense_1_acc_22: 0.1000 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.0500 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.2000 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.1500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s - loss: 104.2312 - dense_1_loss_1: 4.2415 - dense_1_loss_2: 4.0877 - dense_1_loss_3: 3.9055 - dense_1_loss_4: 3.8797 - dense_1_loss_5: 3.7320 - dense_1_loss_6: 3.7342 - dense_1_loss_7: 3.7185 - dense_1_loss_8: 3.5260 - dense_1_loss_9: 3.5839 - dense_1_loss_10: 3.4240 - dense_1_loss_11: 3.5286 - dense_1_loss_12: 3.6576 - dense_1_loss_13: 3.4055 - dense_1_loss_14: 3.3238 - dense_1_loss_15: 3.5095 - dense_1_loss_16: 3.3980 - dense_1_loss_17: 3.4476 - dense_1_loss_18: 3.5165 - dense_1_loss_19: 3.4082 - dense_1_loss_20: 3.5385 - dense_1_loss_21: 3.6156 - dense_1_loss_22: 3.5002 - dense_1_loss_23: 3.5907 - dense_1_loss_24: 3.3992 - dense_1_loss_25: 3.6876 - dense_1_loss_26: 3.3005 - dense_1_loss_27: 3.4814 - dense_1_loss_28: 3.5575 - dense_1_loss_29: 3.5316 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.1667 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.1833 - dense_1_acc_11: 0.1167 - dense_1_acc_12: 0.0833 - dense_1_acc_13: 0.1167 - dense_1_acc_14: 0.1833 - dense_1_acc_15: 0.1000 - dense_1_acc_16: 0.1000 - dense_1_acc_17: 0.2000 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.0833 - dense_1_acc_20: 0.2167 - dense_1_acc_21: 0.1000 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1333 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.2167 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s - loss: 101.0798 - dense_1_loss_1: 4.2282 - dense_1_loss_2: 4.0486 - dense_1_loss_3: 3.8388 - dense_1_loss_4: 3.8112 - dense_1_loss_5: 3.6426 - dense_1_loss_6: 3.6538 - dense_1_loss_7: 3.6311 - dense_1_loss_8: 3.4221 - dense_1_loss_9: 3.4832 - dense_1_loss_10: 3.2979 - dense_1_loss_11: 3.4117 - dense_1_loss_12: 3.5577 - dense_1_loss_13: 3.2735 - dense_1_loss_14: 3.1800 - dense_1_loss_15: 3.3987 - dense_1_loss_16: 3.2829 - dense_1_loss_17: 3.2894 - dense_1_loss_18: 3.4412 - dense_1_loss_19: 3.2517 - dense_1_loss_20: 3.3839 - dense_1_loss_21: 3.4720 - dense_1_loss_22: 3.3767 - dense_1_loss_23: 3.4690 - dense_1_loss_24: 3.3102 - dense_1_loss_25: 3.5363 - dense_1_loss_26: 3.1783 - dense_1_loss_27: 3.3753 - dense_1_loss_28: 3.4000 - dense_1_loss_29: 3.4341 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.1667 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.1000 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.1833 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.2000 - dense_1_acc_14: 0.3000 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.2833 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.2167 - dense_1_acc_21: 0.1667 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.1500 - dense_1_acc_26: 0.2500 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s - loss: 97.2113 - dense_1_loss_1: 4.2165 - dense_1_loss_2: 4.0114 - dense_1_loss_3: 3.7629 - dense_1_loss_4: 3.7428 - dense_1_loss_5: 3.5417 - dense_1_loss_6: 3.5537 - dense_1_loss_7: 3.5138 - dense_1_loss_8: 3.2869 - dense_1_loss_9: 3.3722 - dense_1_loss_10: 3.1639 - dense_1_loss_11: 3.3072 - dense_1_loss_12: 3.4064 - dense_1_loss_13: 3.1292 - dense_1_loss_14: 2.9869 - dense_1_loss_15: 3.2155 - dense_1_loss_16: 3.1257 - dense_1_loss_17: 3.1846 - dense_1_loss_18: 3.2912 - dense_1_loss_19: 3.1634 - dense_1_loss_20: 3.2412 - dense_1_loss_21: 3.3425 - dense_1_loss_22: 3.2471 - dense_1_loss_23: 3.3638 - dense_1_loss_24: 3.1390 - dense_1_loss_25: 3.3034 - dense_1_loss_26: 2.9565 - dense_1_loss_27: 3.1800 - dense_1_loss_28: 3.1918 - dense_1_loss_29: 3.2703 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2167 - dense_1_acc_6: 0.1500 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.1667 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1833 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.2167 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.1333 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.2833 - dense_1_acc_18: 0.2333 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.2167 - dense_1_acc_21: 0.1500 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1667 - dense_1_acc_25: 0.2000 - dense_1_acc_26: 0.3000 - dense_1_acc_27: 0.2000 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s - loss: 93.1183 - dense_1_loss_1: 4.2051 - dense_1_loss_2: 3.9711 - dense_1_loss_3: 3.6821 - dense_1_loss_4: 3.6626 - dense_1_loss_5: 3.4344 - dense_1_loss_6: 3.4380 - dense_1_loss_7: 3.3896 - dense_1_loss_8: 3.1472 - dense_1_loss_9: 3.2215 - dense_1_loss_10: 3.0100 - dense_1_loss_11: 3.1826 - dense_1_loss_12: 3.2494 - dense_1_loss_13: 2.9397 - dense_1_loss_14: 2.7672 - dense_1_loss_15: 3.0429 - dense_1_loss_16: 3.0217 - dense_1_loss_17: 2.9241 - dense_1_loss_18: 3.0916 - dense_1_loss_19: 2.9310 - dense_1_loss_20: 3.1030 - dense_1_loss_21: 3.1494 - dense_1_loss_22: 3.0894 - dense_1_loss_23: 3.2005 - dense_1_loss_24: 3.0120 - dense_1_loss_25: 3.1739 - dense_1_loss_26: 2.8054 - dense_1_loss_27: 3.1047 - dense_1_loss_28: 3.0286 - dense_1_loss_29: 3.1395 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1167 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2333 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.2000 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.2333 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1667 - dense_1_acc_13: 0.2333 - dense_1_acc_14: 0.2833 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.1500 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.2000 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1667 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.2167 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.2667 - dense_1_acc_29: 0.1333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 88.2373 - dense_1_loss_1: 4.1942 - dense_1_loss_2: 3.9291 - dense_1_loss_3: 3.6050 - dense_1_loss_4: 3.5729 - dense_1_loss_5: 3.3157 - dense_1_loss_6: 3.2982 - dense_1_loss_7: 3.2380 - dense_1_loss_8: 3.0094 - dense_1_loss_9: 3.0696 - dense_1_loss_10: 2.8611 - dense_1_loss_11: 3.0122 - dense_1_loss_12: 3.0419 - dense_1_loss_13: 2.7428 - dense_1_loss_14: 2.6033 - dense_1_loss_15: 2.8512 - dense_1_loss_16: 2.9135 - dense_1_loss_17: 2.7593 - dense_1_loss_18: 2.8886 - dense_1_loss_19: 2.8121 - dense_1_loss_20: 2.9340 - dense_1_loss_21: 2.9046 - dense_1_loss_22: 2.8905 - dense_1_loss_23: 2.9519 - dense_1_loss_24: 2.8113 - dense_1_loss_25: 2.9495 - dense_1_loss_26: 2.5961 - dense_1_loss_27: 2.8059 - dense_1_loss_28: 2.8153 - dense_1_loss_29: 2.8599 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2333 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1833 - dense_1_acc_8: 0.1667 - dense_1_acc_9: 0.2000 - dense_1_acc_10: 0.2833 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.2000 - dense_1_acc_13: 0.3500 - dense_1_acc_14: 0.3333 - dense_1_acc_15: 0.2500 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.2500 - dense_1_acc_20: 0.2667 - dense_1_acc_21: 0.2333 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1500 - dense_1_acc_26: 0.2667 - dense_1_acc_27: 0.2500 - dense_1_acc_28: 0.2667 - dense_1_acc_29: 0.1833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s - loss: 83.8858 - dense_1_loss_1: 4.1832 - dense_1_loss_2: 3.8847 - dense_1_loss_3: 3.5192 - dense_1_loss_4: 3.4738 - dense_1_loss_5: 3.1842 - dense_1_loss_6: 3.1371 - dense_1_loss_7: 3.0770 - dense_1_loss_8: 2.8388 - dense_1_loss_9: 2.9216 - dense_1_loss_10: 2.7183 - dense_1_loss_11: 2.8628 - dense_1_loss_12: 2.8371 - dense_1_loss_13: 2.5753 - dense_1_loss_14: 2.5050 - dense_1_loss_15: 2.6743 - dense_1_loss_16: 2.7846 - dense_1_loss_17: 2.6448 - dense_1_loss_18: 2.6631 - dense_1_loss_19: 2.7117 - dense_1_loss_20: 2.7694 - dense_1_loss_21: 2.7082 - dense_1_loss_22: 2.7719 - dense_1_loss_23: 2.7388 - dense_1_loss_24: 2.5420 - dense_1_loss_25: 2.8120 - dense_1_loss_26: 2.4508 - dense_1_loss_27: 2.5579 - dense_1_loss_28: 2.6680 - dense_1_loss_29: 2.6703 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2333 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1833 - dense_1_acc_8: 0.1333 - dense_1_acc_9: 0.2500 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1667 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.3500 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.3167 - dense_1_acc_21: 0.2667 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.2667 - dense_1_acc_24: 0.2667 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.2833 - dense_1_acc_27: 0.3000 - dense_1_acc_28: 0.3333 - dense_1_acc_29: 0.2833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s - loss: 79.8792 - dense_1_loss_1: 4.1714 - dense_1_loss_2: 3.8408 - dense_1_loss_3: 3.4359 - dense_1_loss_4: 3.3702 - dense_1_loss_5: 3.0508 - dense_1_loss_6: 2.9675 - dense_1_loss_7: 2.9115 - dense_1_loss_8: 2.6719 - dense_1_loss_9: 2.7588 - dense_1_loss_10: 2.5682 - dense_1_loss_11: 2.7422 - dense_1_loss_12: 2.6563 - dense_1_loss_13: 2.4079 - dense_1_loss_14: 2.3275 - dense_1_loss_15: 2.5293 - dense_1_loss_16: 2.5943 - dense_1_loss_17: 2.4746 - dense_1_loss_18: 2.5117 - dense_1_loss_19: 2.4794 - dense_1_loss_20: 2.5940 - dense_1_loss_21: 2.5674 - dense_1_loss_22: 2.6363 - dense_1_loss_23: 2.5515 - dense_1_loss_24: 2.4114 - dense_1_loss_25: 2.7162 - dense_1_loss_26: 2.3219 - dense_1_loss_27: 2.5156 - dense_1_loss_28: 2.5572 - dense_1_loss_29: 2.5376 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.2500 - dense_1_acc_7: 0.2333 - dense_1_acc_8: 0.1667 - dense_1_acc_9: 0.2833 - dense_1_acc_10: 0.3500 - dense_1_acc_11: 0.2500 - dense_1_acc_12: 0.2167 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.3333 - dense_1_acc_15: 0.2833 - dense_1_acc_16: 0.3167 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.3333 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.2833 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.3000 - dense_1_acc_24: 0.2333 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.3500 - dense_1_acc_27: 0.3667 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.2333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s - loss: 75.6105 - dense_1_loss_1: 4.1622 - dense_1_loss_2: 3.7951 - dense_1_loss_3: 3.3520 - dense_1_loss_4: 3.2495 - dense_1_loss_5: 2.9210 - dense_1_loss_6: 2.7973 - dense_1_loss_7: 2.7323 - dense_1_loss_8: 2.5163 - dense_1_loss_9: 2.5980 - dense_1_loss_10: 2.4894 - dense_1_loss_11: 2.5823 - dense_1_loss_12: 2.5187 - dense_1_loss_13: 2.2372 - dense_1_loss_14: 2.2220 - dense_1_loss_15: 2.4205 - dense_1_loss_16: 2.4248 - dense_1_loss_17: 2.3390 - dense_1_loss_18: 2.3239 - dense_1_loss_19: 2.3401 - dense_1_loss_20: 2.4082 - dense_1_loss_21: 2.3335 - dense_1_loss_22: 2.3971 - dense_1_loss_23: 2.4673 - dense_1_loss_24: 2.3091 - dense_1_loss_25: 2.4870 - dense_1_loss_26: 2.1749 - dense_1_loss_27: 2.3649 - dense_1_loss_28: 2.3312 - dense_1_loss_29: 2.3155 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.2500 - dense_1_acc_7: 0.3000 - dense_1_acc_8: 0.2500 - dense_1_acc_9: 0.3167 - dense_1_acc_10: 0.3500 - dense_1_acc_11: 0.2833 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.3833 - dense_1_acc_14: 0.3333 - dense_1_acc_15: 0.2833 - dense_1_acc_16: 0.2667 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.3000 - dense_1_acc_19: 0.3167 - dense_1_acc_20: 0.3500 - dense_1_acc_21: 0.3333 - dense_1_acc_22: 0.2667 - dense_1_acc_23: 0.3167 - dense_1_acc_24: 0.3000 - dense_1_acc_25: 0.2333 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.3833 - dense_1_acc_28: 0.3500 - dense_1_acc_29: 0.2833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s - loss: 71.8081 - dense_1_loss_1: 4.1524 - dense_1_loss_2: 3.7499 - dense_1_loss_3: 3.2672 - dense_1_loss_4: 3.1370 - dense_1_loss_5: 2.7801 - dense_1_loss_6: 2.6385 - dense_1_loss_7: 2.5840 - dense_1_loss_8: 2.3807 - dense_1_loss_9: 2.4568 - dense_1_loss_10: 2.3722 - dense_1_loss_11: 2.4757 - dense_1_loss_12: 2.3634 - dense_1_loss_13: 2.0804 - dense_1_loss_14: 2.0624 - dense_1_loss_15: 2.3153 - dense_1_loss_16: 2.3154 - dense_1_loss_17: 2.1537 - dense_1_loss_18: 2.1795 - dense_1_loss_19: 2.1989 - dense_1_loss_20: 2.2638 - dense_1_loss_21: 2.2262 - dense_1_loss_22: 2.2124 - dense_1_loss_23: 2.3655 - dense_1_loss_24: 2.2267 - dense_1_loss_25: 2.4144 - dense_1_loss_26: 1.9703 - dense_1_loss_27: 2.2408 - dense_1_loss_28: 2.0780 - dense_1_loss_29: 2.1465 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.3000 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.3167 - dense_1_acc_11: 0.2667 - dense_1_acc_12: 0.2833 - dense_1_acc_13: 0.4667 - dense_1_acc_14: 0.3833 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.2833 - dense_1_acc_17: 0.3500 - dense_1_acc_18: 0.3333 - dense_1_acc_19: 0.3833 - dense_1_acc_20: 0.3667 - dense_1_acc_21: 0.3667 - dense_1_acc_22: 0.2833 - dense_1_acc_23: 0.3167 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.2333 - dense_1_acc_26: 0.4000 - dense_1_acc_27: 0.4000 - dense_1_acc_28: 0.4000 - dense_1_acc_29: 0.3500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s - loss: 67.8577 - dense_1_loss_1: 4.1428 - dense_1_loss_2: 3.7053 - dense_1_loss_3: 3.1840 - dense_1_loss_4: 3.0138 - dense_1_loss_5: 2.6589 - dense_1_loss_6: 2.4811 - dense_1_loss_7: 2.4516 - dense_1_loss_8: 2.2846 - dense_1_loss_9: 2.2953 - dense_1_loss_10: 2.2723 - dense_1_loss_11: 2.2589 - dense_1_loss_12: 2.2153 - dense_1_loss_13: 1.9549 - dense_1_loss_14: 2.0127 - dense_1_loss_15: 2.1687 - dense_1_loss_16: 2.1122 - dense_1_loss_17: 2.0340 - dense_1_loss_18: 2.0270 - dense_1_loss_19: 2.1177 - dense_1_loss_20: 2.0516 - dense_1_loss_21: 2.0588 - dense_1_loss_22: 2.0757 - dense_1_loss_23: 2.1036 - dense_1_loss_24: 1.9949 - dense_1_loss_25: 2.2056 - dense_1_loss_26: 1.9125 - dense_1_loss_27: 2.0633 - dense_1_loss_28: 1.9660 - dense_1_loss_29: 2.0348 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2500 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.3167 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.4333 - dense_1_acc_10: 0.3833 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.3333 - dense_1_acc_13: 0.4667 - dense_1_acc_14: 0.3333 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.3500 - dense_1_acc_18: 0.3833 - dense_1_acc_19: 0.3500 - dense_1_acc_20: 0.4000 - dense_1_acc_21: 0.3500 - dense_1_acc_22: 0.2667 - dense_1_acc_23: 0.3500 - dense_1_acc_24: 0.3667 - dense_1_acc_25: 0.2167 - dense_1_acc_26: 0.4000 - dense_1_acc_27: 0.4500 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.3333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s - loss: 64.2681 - dense_1_loss_1: 4.1333 - dense_1_loss_2: 3.6588 - dense_1_loss_3: 3.0964 - dense_1_loss_4: 2.8891 - dense_1_loss_5: 2.5130 - dense_1_loss_6: 2.3250 - dense_1_loss_7: 2.3102 - dense_1_loss_8: 2.1184 - dense_1_loss_9: 2.1931 - dense_1_loss_10: 2.2057 - dense_1_loss_11: 2.1176 - dense_1_loss_12: 2.0214 - dense_1_loss_13: 1.8218 - dense_1_loss_14: 1.8588 - dense_1_loss_15: 1.9490 - dense_1_loss_16: 1.9230 - dense_1_loss_17: 1.9140 - dense_1_loss_18: 1.9710 - dense_1_loss_19: 1.9949 - dense_1_loss_20: 1.9142 - dense_1_loss_21: 1.9704 - dense_1_loss_22: 1.9316 - dense_1_loss_23: 1.9927 - dense_1_loss_24: 1.9246 - dense_1_loss_25: 2.0163 - dense_1_loss_26: 1.8051 - dense_1_loss_27: 1.9156 - dense_1_loss_28: 1.8620 - dense_1_loss_29: 1.9209 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2500 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2833 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3667 - dense_1_acc_7: 0.3000 - dense_1_acc_8: 0.4167 - dense_1_acc_9: 0.4000 - dense_1_acc_10: 0.3667 - dense_1_acc_11: 0.3500 - dense_1_acc_12: 0.3500 - dense_1_acc_13: 0.5333 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.4500 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.4167 - dense_1_acc_18: 0.4333 - dense_1_acc_19: 0.4333 - dense_1_acc_20: 0.4667 - dense_1_acc_21: 0.3667 - dense_1_acc_22: 0.4000 - dense_1_acc_23: 0.3667 - dense_1_acc_24: 0.3667 - dense_1_acc_25: 0.3500 - dense_1_acc_26: 0.5000 - dense_1_acc_27: 0.5500 - dense_1_acc_28: 0.5167 - dense_1_acc_29: 0.5167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s - loss: 60.7105 - dense_1_loss_1: 4.1228 - dense_1_loss_2: 3.6090 - dense_1_loss_3: 3.0059 - dense_1_loss_4: 2.7688 - dense_1_loss_5: 2.3884 - dense_1_loss_6: 2.2003 - dense_1_loss_7: 2.1667 - dense_1_loss_8: 2.0035 - dense_1_loss_9: 2.0013 - dense_1_loss_10: 2.0320 - dense_1_loss_11: 1.9270 - dense_1_loss_12: 1.8702 - dense_1_loss_13: 1.7217 - dense_1_loss_14: 1.8034 - dense_1_loss_15: 1.8394 - dense_1_loss_16: 1.8249 - dense_1_loss_17: 1.7537 - dense_1_loss_18: 1.8074 - dense_1_loss_19: 1.8393 - dense_1_loss_20: 1.7368 - dense_1_loss_21: 1.8130 - dense_1_loss_22: 1.8491 - dense_1_loss_23: 1.8258 - dense_1_loss_24: 1.7558 - dense_1_loss_25: 1.9191 - dense_1_loss_26: 1.6654 - dense_1_loss_27: 1.8306 - dense_1_loss_28: 1.8219 - dense_1_loss_29: 1.8075 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.4500 - dense_1_acc_7: 0.3667 - dense_1_acc_8: 0.3833 - dense_1_acc_9: 0.4667 - dense_1_acc_10: 0.4000 - dense_1_acc_11: 0.3667 - dense_1_acc_12: 0.4333 - dense_1_acc_13: 0.5333 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.4167 - dense_1_acc_16: 0.4333 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.4500 - dense_1_acc_19: 0.4833 - dense_1_acc_20: 0.5333 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.4333 - dense_1_acc_23: 0.4667 - dense_1_acc_24: 0.4833 - dense_1_acc_25: 0.4000 - dense_1_acc_26: 0.5667 - dense_1_acc_27: 0.4667 - dense_1_acc_28: 0.4500 - dense_1_acc_29: 0.5333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s - loss: 57.4640 - dense_1_loss_1: 4.1124 - dense_1_loss_2: 3.5617 - dense_1_loss_3: 2.9166 - dense_1_loss_4: 2.6513 - dense_1_loss_5: 2.2783 - dense_1_loss_6: 2.1045 - dense_1_loss_7: 2.0097 - dense_1_loss_8: 1.8761 - dense_1_loss_9: 1.9255 - dense_1_loss_10: 1.9042 - dense_1_loss_11: 1.8216 - dense_1_loss_12: 1.7717 - dense_1_loss_13: 1.5828 - dense_1_loss_14: 1.6442 - dense_1_loss_15: 1.8107 - dense_1_loss_16: 1.6730 - dense_1_loss_17: 1.6504 - dense_1_loss_18: 1.7303 - dense_1_loss_19: 1.7075 - dense_1_loss_20: 1.5822 - dense_1_loss_21: 1.6596 - dense_1_loss_22: 1.7499 - dense_1_loss_23: 1.6826 - dense_1_loss_24: 1.6388 - dense_1_loss_25: 1.7975 - dense_1_loss_26: 1.5960 - dense_1_loss_27: 1.6766 - dense_1_loss_28: 1.6724 - dense_1_loss_29: 1.6758 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.4167 - dense_1_acc_6: 0.4833 - dense_1_acc_7: 0.4167 - dense_1_acc_8: 0.4500 - dense_1_acc_9: 0.4833 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.4667 - dense_1_acc_13: 0.6167 - dense_1_acc_14: 0.5333 - dense_1_acc_15: 0.3833 - dense_1_acc_16: 0.4333 - dense_1_acc_17: 0.5667 - dense_1_acc_18: 0.5000 - dense_1_acc_19: 0.5833 - dense_1_acc_20: 0.6333 - dense_1_acc_21: 0.5333 - dense_1_acc_22: 0.4667 - dense_1_acc_23: 0.5500 - dense_1_acc_24: 0.4833 - dense_1_acc_25: 0.4000 - dense_1_acc_26: 0.5833 - dense_1_acc_27: 0.5500 - dense_1_acc_28: 0.5333 - dense_1_acc_29: 0.5833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s - loss: 55.3001 - dense_1_loss_1: 4.1028 - dense_1_loss_2: 3.5122 - dense_1_loss_3: 2.8178 - dense_1_loss_4: 2.5413 - dense_1_loss_5: 2.1938 - dense_1_loss_6: 1.9830 - dense_1_loss_7: 1.8772 - dense_1_loss_8: 1.7926 - dense_1_loss_9: 1.7852 - dense_1_loss_10: 1.7737 - dense_1_loss_11: 1.7929 - dense_1_loss_12: 1.7002 - dense_1_loss_13: 1.5321 - dense_1_loss_14: 1.5986 - dense_1_loss_15: 1.7045 - dense_1_loss_16: 1.6925 - dense_1_loss_17: 1.5769 - dense_1_loss_18: 1.5430 - dense_1_loss_19: 1.6889 - dense_1_loss_20: 1.5281 - dense_1_loss_21: 1.6284 - dense_1_loss_22: 1.6649 - dense_1_loss_23: 1.6183 - dense_1_loss_24: 1.5516 - dense_1_loss_25: 1.6758 - dense_1_loss_26: 1.5755 - dense_1_loss_27: 1.6385 - dense_1_loss_28: 1.6163 - dense_1_loss_29: 1.5936 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2833 - dense_1_acc_5: 0.4167 - dense_1_acc_6: 0.5333 - dense_1_acc_7: 0.4667 - dense_1_acc_8: 0.5333 - dense_1_acc_9: 0.5167 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.5167 - dense_1_acc_12: 0.4833 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.6000 - dense_1_acc_15: 0.5167 - dense_1_acc_16: 0.5000 - dense_1_acc_17: 0.6167 - dense_1_acc_18: 0.5833 - dense_1_acc_19: 0.5333 - dense_1_acc_20: 0.6333 - dense_1_acc_21: 0.5833 - dense_1_acc_22: 0.4167 - dense_1_acc_23: 0.5500 - dense_1_acc_24: 0.5500 - dense_1_acc_25: 0.4000 - dense_1_acc_26: 0.5167 - dense_1_acc_27: 0.6000 - dense_1_acc_28: 0.6500 - dense_1_acc_29: 0.6167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 52.6321 - dense_1_loss_1: 4.0937 - dense_1_loss_2: 3.4661 - dense_1_loss_3: 2.7182 - dense_1_loss_4: 2.4315 - dense_1_loss_5: 2.0864 - dense_1_loss_6: 1.8641 - dense_1_loss_7: 1.7451 - dense_1_loss_8: 1.7077 - dense_1_loss_9: 1.6944 - dense_1_loss_10: 1.6402 - dense_1_loss_11: 1.6513 - dense_1_loss_12: 1.5936 - dense_1_loss_13: 1.3844 - dense_1_loss_14: 1.4632 - dense_1_loss_15: 1.6363 - dense_1_loss_16: 1.5388 - dense_1_loss_17: 1.5022 - dense_1_loss_18: 1.4763 - dense_1_loss_19: 1.4810 - dense_1_loss_20: 1.4449 - dense_1_loss_21: 1.5147 - dense_1_loss_22: 1.5778 - dense_1_loss_23: 1.5917 - dense_1_loss_24: 1.5977 - dense_1_loss_25: 1.6043 - dense_1_loss_26: 1.4948 - dense_1_loss_27: 1.5242 - dense_1_loss_28: 1.5365 - dense_1_loss_29: 1.5710 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.4000 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.5167 - dense_1_acc_7: 0.5500 - dense_1_acc_8: 0.5667 - dense_1_acc_9: 0.5500 - dense_1_acc_10: 0.4833 - dense_1_acc_11: 0.4667 - dense_1_acc_12: 0.5833 - dense_1_acc_13: 0.7500 - dense_1_acc_14: 0.6333 - dense_1_acc_15: 0.5000 - dense_1_acc_16: 0.5833 - dense_1_acc_17: 0.6000 - dense_1_acc_18: 0.5667 - dense_1_acc_19: 0.6333 - dense_1_acc_20: 0.7000 - dense_1_acc_21: 0.5333 - dense_1_acc_22: 0.5333 - dense_1_acc_23: 0.4667 - dense_1_acc_24: 0.5500 - dense_1_acc_25: 0.5000 - dense_1_acc_26: 0.6000 - dense_1_acc_27: 0.6000 - dense_1_acc_28: 0.5833 - dense_1_acc_29: 0.6500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s - loss: 49.4006 - dense_1_loss_1: 4.0845 - dense_1_loss_2: 3.4178 - dense_1_loss_3: 2.6303 - dense_1_loss_4: 2.3310 - dense_1_loss_5: 1.9913 - dense_1_loss_6: 1.7646 - dense_1_loss_7: 1.6366 - dense_1_loss_8: 1.6252 - dense_1_loss_9: 1.5813 - dense_1_loss_10: 1.5285 - dense_1_loss_11: 1.5215 - dense_1_loss_12: 1.4977 - dense_1_loss_13: 1.2712 - dense_1_loss_14: 1.3591 - dense_1_loss_15: 1.4544 - dense_1_loss_16: 1.4537 - dense_1_loss_17: 1.4107 - dense_1_loss_18: 1.3646 - dense_1_loss_19: 1.4194 - dense_1_loss_20: 1.3501 - dense_1_loss_21: 1.4296 - dense_1_loss_22: 1.4543 - dense_1_loss_23: 1.4621 - dense_1_loss_24: 1.3821 - dense_1_loss_25: 1.4126 - dense_1_loss_26: 1.3559 - dense_1_loss_27: 1.3946 - dense_1_loss_28: 1.4274 - dense_1_loss_29: 1.3885 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.5167 - dense_1_acc_7: 0.6333 - dense_1_acc_8: 0.6000 - dense_1_acc_9: 0.6167 - dense_1_acc_10: 0.6167 - dense_1_acc_11: 0.5500 - dense_1_acc_12: 0.6500 - dense_1_acc_13: 0.7667 - dense_1_acc_14: 0.6833 - dense_1_acc_15: 0.5500 - dense_1_acc_16: 0.5667 - dense_1_acc_17: 0.5833 - dense_1_acc_18: 0.6167 - dense_1_acc_19: 0.6167 - dense_1_acc_20: 0.7000 - dense_1_acc_21: 0.5833 - dense_1_acc_22: 0.5833 - dense_1_acc_23: 0.5500 - dense_1_acc_24: 0.5833 - dense_1_acc_25: 0.5667 - dense_1_acc_26: 0.7000 - dense_1_acc_27: 0.6500 - dense_1_acc_28: 0.6333 - dense_1_acc_29: 0.7167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s - loss: 47.2301 - dense_1_loss_1: 4.0738 - dense_1_loss_2: 3.3668 - dense_1_loss_3: 2.5425 - dense_1_loss_4: 2.2374 - dense_1_loss_5: 1.9165 - dense_1_loss_6: 1.6859 - dense_1_loss_7: 1.5545 - dense_1_loss_8: 1.5690 - dense_1_loss_9: 1.4632 - dense_1_loss_10: 1.3719 - dense_1_loss_11: 1.4403 - dense_1_loss_12: 1.3852 - dense_1_loss_13: 1.1968 - dense_1_loss_14: 1.2689 - dense_1_loss_15: 1.3509 - dense_1_loss_16: 1.3903 - dense_1_loss_17: 1.2932 - dense_1_loss_18: 1.3276 - dense_1_loss_19: 1.3312 - dense_1_loss_20: 1.2508 - dense_1_loss_21: 1.3817 - dense_1_loss_22: 1.4141 - dense_1_loss_23: 1.3944 - dense_1_loss_24: 1.3149 - dense_1_loss_25: 1.3502 - dense_1_loss_26: 1.2831 - dense_1_loss_27: 1.3523 - dense_1_loss_28: 1.3877 - dense_1_loss_29: 1.3348 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.2833 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.5000 - dense_1_acc_7: 0.6500 - dense_1_acc_8: 0.6000 - dense_1_acc_9: 0.6667 - dense_1_acc_10: 0.6667 - dense_1_acc_11: 0.5500 - dense_1_acc_12: 0.6333 - dense_1_acc_13: 0.7667 - dense_1_acc_14: 0.6667 - dense_1_acc_15: 0.5500 - dense_1_acc_16: 0.5833 - dense_1_acc_17: 0.7167 - dense_1_acc_18: 0.6333 - dense_1_acc_19: 0.6833 - dense_1_acc_20: 0.7167 - dense_1_acc_21: 0.6333 - dense_1_acc_22: 0.5833 - dense_1_acc_23: 0.6000 - dense_1_acc_24: 0.6667 - dense_1_acc_25: 0.5833 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.6000 - dense_1_acc_28: 0.6667 - dense_1_acc_29: 0.7167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s - loss: 44.2707 - dense_1_loss_1: 4.0658 - dense_1_loss_2: 3.3206 - dense_1_loss_3: 2.4574 - dense_1_loss_4: 2.1434 - dense_1_loss_5: 1.8275 - dense_1_loss_6: 1.6017 - dense_1_loss_7: 1.4556 - dense_1_loss_8: 1.4584 - dense_1_loss_9: 1.3916 - dense_1_loss_10: 1.3130 - dense_1_loss_11: 1.3413 - dense_1_loss_12: 1.2637 - dense_1_loss_13: 1.1105 - dense_1_loss_14: 1.1767 - dense_1_loss_15: 1.2429 - dense_1_loss_16: 1.2787 - dense_1_loss_17: 1.1752 - dense_1_loss_18: 1.1991 - dense_1_loss_19: 1.1964 - dense_1_loss_20: 1.1691 - dense_1_loss_21: 1.2304 - dense_1_loss_22: 1.2682 - dense_1_loss_23: 1.2458 - dense_1_loss_24: 1.2279 - dense_1_loss_25: 1.2317 - dense_1_loss_26: 1.1826 - dense_1_loss_27: 1.2186 - dense_1_loss_28: 1.2614 - dense_1_loss_29: 1.2156 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.4667 - dense_1_acc_6: 0.5167 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.6833 - dense_1_acc_10: 0.7167 - dense_1_acc_11: 0.6667 - dense_1_acc_12: 0.7000 - dense_1_acc_13: 0.8167 - dense_1_acc_14: 0.7833 - dense_1_acc_15: 0.6833 - dense_1_acc_16: 0.6333 - dense_1_acc_17: 0.7667 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.7833 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.7833 - dense_1_acc_22: 0.7333 - dense_1_acc_23: 0.7167 - dense_1_acc_24: 0.7333 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8000 - dense_1_acc_27: 0.7000 - dense_1_acc_28: 0.7333 - dense_1_acc_29: 0.7833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s - loss: 42.0745 - dense_1_loss_1: 4.0575 - dense_1_loss_2: 3.2711 - dense_1_loss_3: 2.3796 - dense_1_loss_4: 2.0418 - dense_1_loss_5: 1.7499 - dense_1_loss_6: 1.5101 - dense_1_loss_7: 1.3693 - dense_1_loss_8: 1.3816 - dense_1_loss_9: 1.3026 - dense_1_loss_10: 1.2433 - dense_1_loss_11: 1.2346 - dense_1_loss_12: 1.1377 - dense_1_loss_13: 1.0222 - dense_1_loss_14: 1.0575 - dense_1_loss_15: 1.1949 - dense_1_loss_16: 1.2108 - dense_1_loss_17: 1.0845 - dense_1_loss_18: 1.0950 - dense_1_loss_19: 1.1171 - dense_1_loss_20: 1.1121 - dense_1_loss_21: 1.1442 - dense_1_loss_22: 1.2167 - dense_1_loss_23: 1.1930 - dense_1_loss_24: 1.1523 - dense_1_loss_25: 1.1809 - dense_1_loss_26: 1.1148 - dense_1_loss_27: 1.1821 - dense_1_loss_28: 1.1606 - dense_1_loss_29: 1.1568 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.5000 - dense_1_acc_6: 0.5667 - dense_1_acc_7: 0.7333 - dense_1_acc_8: 0.7000 - dense_1_acc_9: 0.6500 - dense_1_acc_10: 0.6833 - dense_1_acc_11: 0.7333 - dense_1_acc_12: 0.7667 - dense_1_acc_13: 0.8500 - dense_1_acc_14: 0.7667 - dense_1_acc_15: 0.7000 - dense_1_acc_16: 0.7000 - dense_1_acc_17: 0.7833 - dense_1_acc_18: 0.8167 - dense_1_acc_19: 0.8167 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.8167 - dense_1_acc_22: 0.7833 - dense_1_acc_23: 0.7000 - dense_1_acc_24: 0.7667 - dense_1_acc_25: 0.7667 - dense_1_acc_26: 0.8667 - dense_1_acc_27: 0.7500 - dense_1_acc_28: 0.7833 - dense_1_acc_29: 0.8167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s - loss: 39.7990 - dense_1_loss_1: 4.0490 - dense_1_loss_2: 3.2205 - dense_1_loss_3: 2.2978 - dense_1_loss_4: 1.9498 - dense_1_loss_5: 1.6803 - dense_1_loss_6: 1.4169 - dense_1_loss_7: 1.2708 - dense_1_loss_8: 1.2908 - dense_1_loss_9: 1.1945 - dense_1_loss_10: 1.1398 - dense_1_loss_11: 1.1274 - dense_1_loss_12: 1.0556 - dense_1_loss_13: 0.9721 - dense_1_loss_14: 0.9817 - dense_1_loss_15: 1.1347 - dense_1_loss_16: 1.0934 - dense_1_loss_17: 1.0165 - dense_1_loss_18: 1.0373 - dense_1_loss_19: 1.0041 - dense_1_loss_20: 1.0632 - dense_1_loss_21: 1.0610 - dense_1_loss_22: 1.1015 - dense_1_loss_23: 1.1281 - dense_1_loss_24: 1.0793 - dense_1_loss_25: 1.0970 - dense_1_loss_26: 1.0371 - dense_1_loss_27: 1.0966 - dense_1_loss_28: 1.1154 - dense_1_loss_29: 1.0868 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4667 - dense_1_acc_4: 0.4167 - dense_1_acc_5: 0.5000 - dense_1_acc_6: 0.6167 - dense_1_acc_7: 0.7333 - dense_1_acc_8: 0.7500 - dense_1_acc_9: 0.7500 - dense_1_acc_10: 0.8000 - dense_1_acc_11: 0.8000 - dense_1_acc_12: 0.8167 - dense_1_acc_13: 0.8500 - dense_1_acc_14: 0.8167 - dense_1_acc_15: 0.7333 - dense_1_acc_16: 0.8333 - dense_1_acc_17: 0.8167 - dense_1_acc_18: 0.8500 - dense_1_acc_19: 0.9000 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.8333 - dense_1_acc_22: 0.8333 - dense_1_acc_23: 0.8167 - dense_1_acc_24: 0.8167 - dense_1_acc_25: 0.7667 - dense_1_acc_26: 0.8833 - dense_1_acc_27: 0.8833 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.8500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s - loss: 37.7260 - dense_1_loss_1: 4.0400 - dense_1_loss_2: 3.1726 - dense_1_loss_3: 2.2252 - dense_1_loss_4: 1.8587 - dense_1_loss_5: 1.6162 - dense_1_loss_6: 1.3574 - dense_1_loss_7: 1.1990 - dense_1_loss_8: 1.2378 - dense_1_loss_9: 1.0789 - dense_1_loss_10: 1.0529 - dense_1_loss_11: 1.0574 - dense_1_loss_12: 1.0061 - dense_1_loss_13: 0.9208 - dense_1_loss_14: 0.9316 - dense_1_loss_15: 1.0588 - dense_1_loss_16: 0.9945 - dense_1_loss_17: 0.9600 - dense_1_loss_18: 0.9542 - dense_1_loss_19: 0.9737 - dense_1_loss_20: 0.9921 - dense_1_loss_21: 0.9604 - dense_1_loss_22: 1.0182 - dense_1_loss_23: 1.0344 - dense_1_loss_24: 0.9928 - dense_1_loss_25: 1.0515 - dense_1_loss_26: 0.9906 - dense_1_loss_27: 0.9754 - dense_1_loss_28: 1.0350 - dense_1_loss_29: 0.9797 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4833 - dense_1_acc_4: 0.4333 - dense_1_acc_5: 0.5000 - dense_1_acc_6: 0.6500 - dense_1_acc_7: 0.7333 - dense_1_acc_8: 0.7500 - dense_1_acc_9: 0.8500 - dense_1_acc_10: 0.7667 - dense_1_acc_11: 0.8333 - dense_1_acc_12: 0.8167 - dense_1_acc_13: 0.9167 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.8000 - dense_1_acc_16: 0.9000 - dense_1_acc_17: 0.9000 - dense_1_acc_18: 0.9000 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.8833 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.8333 - dense_1_acc_23: 0.7833 - dense_1_acc_24: 0.8333 - dense_1_acc_25: 0.7667 - dense_1_acc_26: 0.9000 - dense_1_acc_27: 0.9000 - dense_1_acc_28: 0.8167 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s - loss: 35.7787 - dense_1_loss_1: 4.0315 - dense_1_loss_2: 3.1255 - dense_1_loss_3: 2.1467 - dense_1_loss_4: 1.7689 - dense_1_loss_5: 1.5438 - dense_1_loss_6: 1.2785 - dense_1_loss_7: 1.1061 - dense_1_loss_8: 1.1732 - dense_1_loss_9: 0.9794 - dense_1_loss_10: 0.9589 - dense_1_loss_11: 0.9754 - dense_1_loss_12: 0.9248 - dense_1_loss_13: 0.8597 - dense_1_loss_14: 0.8534 - dense_1_loss_15: 0.9682 - dense_1_loss_16: 0.9276 - dense_1_loss_17: 0.8825 - dense_1_loss_18: 0.8770 - dense_1_loss_19: 0.9117 - dense_1_loss_20: 0.9303 - dense_1_loss_21: 0.9111 - dense_1_loss_22: 0.9574 - dense_1_loss_23: 0.9672 - dense_1_loss_24: 0.9450 - dense_1_loss_25: 0.9799 - dense_1_loss_26: 0.9430 - dense_1_loss_27: 0.9209 - dense_1_loss_28: 0.9974 - dense_1_loss_29: 0.9338 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.5167 - dense_1_acc_4: 0.4667 - dense_1_acc_5: 0.5167 - dense_1_acc_6: 0.6667 - dense_1_acc_7: 0.7333 - dense_1_acc_8: 0.7833 - dense_1_acc_9: 0.8500 - dense_1_acc_10: 0.9000 - dense_1_acc_11: 0.8500 - dense_1_acc_12: 0.8833 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9333 - dense_1_acc_15: 0.8667 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9500 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9167 - dense_1_acc_21: 0.9000 - dense_1_acc_22: 0.9167 - dense_1_acc_23: 0.9167 - dense_1_acc_24: 0.8667 - dense_1_acc_25: 0.8333 - dense_1_acc_26: 0.8667 - dense_1_acc_27: 0.9333 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s - loss: 33.8989 - dense_1_loss_1: 4.0243 - dense_1_loss_2: 3.0820 - dense_1_loss_3: 2.0701 - dense_1_loss_4: 1.6790 - dense_1_loss_5: 1.4574 - dense_1_loss_6: 1.1864 - dense_1_loss_7: 1.0252 - dense_1_loss_8: 1.0735 - dense_1_loss_9: 0.9461 - dense_1_loss_10: 0.8982 - dense_1_loss_11: 0.8968 - dense_1_loss_12: 0.8611 - dense_1_loss_13: 0.7920 - dense_1_loss_14: 0.7986 - dense_1_loss_15: 0.8716 - dense_1_loss_16: 0.8795 - dense_1_loss_17: 0.8357 - dense_1_loss_18: 0.8360 - dense_1_loss_19: 0.8499 - dense_1_loss_20: 0.8669 - dense_1_loss_21: 0.8563 - dense_1_loss_22: 0.8962 - dense_1_loss_23: 0.9064 - dense_1_loss_24: 0.8701 - dense_1_loss_25: 0.8877 - dense_1_loss_26: 0.8730 - dense_1_loss_27: 0.8650 - dense_1_loss_28: 0.9429 - dense_1_loss_29: 0.8709 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4667 - dense_1_acc_5: 0.5667 - dense_1_acc_6: 0.7167 - dense_1_acc_7: 0.8333 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.9167 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9667 - dense_1_acc_19: 0.9333 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.9333 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9667 - dense_1_acc_28: 0.9000 - dense_1_acc_29: 0.9167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s - loss: 32.0698 - dense_1_loss_1: 4.0175 - dense_1_loss_2: 3.0315 - dense_1_loss_3: 1.9971 - dense_1_loss_4: 1.5919 - dense_1_loss_5: 1.3842 - dense_1_loss_6: 1.1129 - dense_1_loss_7: 0.9698 - dense_1_loss_8: 1.0150 - dense_1_loss_9: 0.8648 - dense_1_loss_10: 0.8421 - dense_1_loss_11: 0.8070 - dense_1_loss_12: 0.8022 - dense_1_loss_13: 0.7292 - dense_1_loss_14: 0.7286 - dense_1_loss_15: 0.8247 - dense_1_loss_16: 0.8257 - dense_1_loss_17: 0.7578 - dense_1_loss_18: 0.7726 - dense_1_loss_19: 0.7854 - dense_1_loss_20: 0.7869 - dense_1_loss_21: 0.8174 - dense_1_loss_22: 0.8393 - dense_1_loss_23: 0.8515 - dense_1_loss_24: 0.8069 - dense_1_loss_25: 0.8028 - dense_1_loss_26: 0.8061 - dense_1_loss_27: 0.8187 - dense_1_loss_28: 0.8655 - dense_1_loss_29: 0.8144 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.4667 - dense_1_acc_5: 0.5833 - dense_1_acc_6: 0.7167 - dense_1_acc_7: 0.8667 - dense_1_acc_8: 0.8000 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.9167 - dense_1_acc_11: 0.9000 - dense_1_acc_12: 0.9333 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.9167 - dense_1_acc_24: 0.9500 - dense_1_acc_25: 0.9833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 30.4029 - dense_1_loss_1: 4.0098 - dense_1_loss_2: 2.9843 - dense_1_loss_3: 1.9273 - dense_1_loss_4: 1.5057 - dense_1_loss_5: 1.3138 - dense_1_loss_6: 1.0381 - dense_1_loss_7: 0.8941 - dense_1_loss_8: 0.9426 - dense_1_loss_9: 0.8094 - dense_1_loss_10: 0.7931 - dense_1_loss_11: 0.7802 - dense_1_loss_12: 0.7263 - dense_1_loss_13: 0.6857 - dense_1_loss_14: 0.6751 - dense_1_loss_15: 0.7752 - dense_1_loss_16: 0.7636 - dense_1_loss_17: 0.7017 - dense_1_loss_18: 0.7140 - dense_1_loss_19: 0.7055 - dense_1_loss_20: 0.7594 - dense_1_loss_21: 0.7561 - dense_1_loss_22: 0.7636 - dense_1_loss_23: 0.8013 - dense_1_loss_24: 0.7496 - dense_1_loss_25: 0.7359 - dense_1_loss_26: 0.7460 - dense_1_loss_27: 0.7637 - dense_1_loss_28: 0.8184 - dense_1_loss_29: 0.7634 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.5833 - dense_1_acc_4: 0.5167 - dense_1_acc_5: 0.5833 - dense_1_acc_6: 0.7667 - dense_1_acc_7: 0.8833 - dense_1_acc_8: 0.8667 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9667 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 0.9667 - dense_1_acc_23: 0.9333 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s - loss: 28.7416 - dense_1_loss_1: 4.0023 - dense_1_loss_2: 2.9328 - dense_1_loss_3: 1.8592 - dense_1_loss_4: 1.4293 - dense_1_loss_5: 1.2485 - dense_1_loss_6: 0.9634 - dense_1_loss_7: 0.8425 - dense_1_loss_8: 0.8619 - dense_1_loss_9: 0.7571 - dense_1_loss_10: 0.7370 - dense_1_loss_11: 0.7122 - dense_1_loss_12: 0.6845 - dense_1_loss_13: 0.6202 - dense_1_loss_14: 0.6245 - dense_1_loss_15: 0.6968 - dense_1_loss_16: 0.7030 - dense_1_loss_17: 0.6739 - dense_1_loss_18: 0.6503 - dense_1_loss_19: 0.6920 - dense_1_loss_20: 0.7011 - dense_1_loss_21: 0.6934 - dense_1_loss_22: 0.7342 - dense_1_loss_23: 0.7056 - dense_1_loss_24: 0.6877 - dense_1_loss_25: 0.6788 - dense_1_loss_26: 0.6942 - dense_1_loss_27: 0.6901 - dense_1_loss_28: 0.7576 - dense_1_loss_29: 0.7075 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.5833 - dense_1_acc_5: 0.6167 - dense_1_acc_6: 0.8167 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9667 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s - loss: 27.2062 - dense_1_loss_1: 3.9958 - dense_1_loss_2: 2.8813 - dense_1_loss_3: 1.7925 - dense_1_loss_4: 1.3544 - dense_1_loss_5: 1.1924 - dense_1_loss_6: 0.8850 - dense_1_loss_7: 0.7880 - dense_1_loss_8: 0.8163 - dense_1_loss_9: 0.6784 - dense_1_loss_10: 0.6794 - dense_1_loss_11: 0.6382 - dense_1_loss_12: 0.6203 - dense_1_loss_13: 0.5657 - dense_1_loss_14: 0.5677 - dense_1_loss_15: 0.6418 - dense_1_loss_16: 0.6281 - dense_1_loss_17: 0.6110 - dense_1_loss_18: 0.5915 - dense_1_loss_19: 0.6539 - dense_1_loss_20: 0.6470 - dense_1_loss_21: 0.6376 - dense_1_loss_22: 0.6715 - dense_1_loss_23: 0.6705 - dense_1_loss_24: 0.6532 - dense_1_loss_25: 0.6417 - dense_1_loss_26: 0.6466 - dense_1_loss_27: 0.6604 - dense_1_loss_28: 0.7315 - dense_1_loss_29: 0.6645 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.6000 - dense_1_acc_5: 0.6500 - dense_1_acc_6: 0.8167 - dense_1_acc_7: 0.9167 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 0.9667 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9833 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9667 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s - loss: 25.6702 - dense_1_loss_1: 3.9887 - dense_1_loss_2: 2.8353 - dense_1_loss_3: 1.7311 - dense_1_loss_4: 1.2847 - dense_1_loss_5: 1.1229 - dense_1_loss_6: 0.8211 - dense_1_loss_7: 0.7258 - dense_1_loss_8: 0.7458 - dense_1_loss_9: 0.6437 - dense_1_loss_10: 0.6268 - dense_1_loss_11: 0.5996 - dense_1_loss_12: 0.5643 - dense_1_loss_13: 0.5263 - dense_1_loss_14: 0.5293 - dense_1_loss_15: 0.6014 - dense_1_loss_16: 0.5847 - dense_1_loss_17: 0.5503 - dense_1_loss_18: 0.5483 - dense_1_loss_19: 0.6045 - dense_1_loss_20: 0.5973 - dense_1_loss_21: 0.5846 - dense_1_loss_22: 0.5996 - dense_1_loss_23: 0.6173 - dense_1_loss_24: 0.5993 - dense_1_loss_25: 0.5674 - dense_1_loss_26: 0.5976 - dense_1_loss_27: 0.5941 - dense_1_loss_28: 0.6783 - dense_1_loss_29: 0.6001 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.6333 - dense_1_acc_5: 0.6667 - dense_1_acc_6: 0.8500 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s - loss: 24.3247 - dense_1_loss_1: 3.9817 - dense_1_loss_2: 2.7874 - dense_1_loss_3: 1.6685 - dense_1_loss_4: 1.2130 - dense_1_loss_5: 1.0662 - dense_1_loss_6: 0.7708 - dense_1_loss_7: 0.6695 - dense_1_loss_8: 0.6951 - dense_1_loss_9: 0.5981 - dense_1_loss_10: 0.5844 - dense_1_loss_11: 0.5461 - dense_1_loss_12: 0.5315 - dense_1_loss_13: 0.4854 - dense_1_loss_14: 0.4805 - dense_1_loss_15: 0.5718 - dense_1_loss_16: 0.5425 - dense_1_loss_17: 0.5035 - dense_1_loss_18: 0.5234 - dense_1_loss_19: 0.5517 - dense_1_loss_20: 0.5525 - dense_1_loss_21: 0.5441 - dense_1_loss_22: 0.5580 - dense_1_loss_23: 0.5680 - dense_1_loss_24: 0.5387 - dense_1_loss_25: 0.5221 - dense_1_loss_26: 0.5557 - dense_1_loss_27: 0.5420 - dense_1_loss_28: 0.6054 - dense_1_loss_29: 0.5671 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.6333 - dense_1_acc_5: 0.7333 - dense_1_acc_6: 0.8833 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s - loss: 23.0083 - dense_1_loss_1: 3.9755 - dense_1_loss_2: 2.7421 - dense_1_loss_3: 1.6087 - dense_1_loss_4: 1.1521 - dense_1_loss_5: 1.0069 - dense_1_loss_6: 0.7043 - dense_1_loss_7: 0.6179 - dense_1_loss_8: 0.6367 - dense_1_loss_9: 0.5188 - dense_1_loss_10: 0.5308 - dense_1_loss_11: 0.4899 - dense_1_loss_12: 0.4915 - dense_1_loss_13: 0.4459 - dense_1_loss_14: 0.4216 - dense_1_loss_15: 0.5352 - dense_1_loss_16: 0.4778 - dense_1_loss_17: 0.4586 - dense_1_loss_18: 0.4850 - dense_1_loss_19: 0.5106 - dense_1_loss_20: 0.5058 - dense_1_loss_21: 0.5083 - dense_1_loss_22: 0.5134 - dense_1_loss_23: 0.5427 - dense_1_loss_24: 0.4965 - dense_1_loss_25: 0.4940 - dense_1_loss_26: 0.5203 - dense_1_loss_27: 0.5134 - dense_1_loss_28: 0.5699 - dense_1_loss_29: 0.5343 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.6667 - dense_1_acc_5: 0.7333 - dense_1_acc_6: 0.9000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 0.9667 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 0.9500 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s - loss: 21.7588 - dense_1_loss_1: 3.9690 - dense_1_loss_2: 2.6973 - dense_1_loss_3: 1.5506 - dense_1_loss_4: 1.0914 - dense_1_loss_5: 0.9426 - dense_1_loss_6: 0.6570 - dense_1_loss_7: 0.5745 - dense_1_loss_8: 0.5890 - dense_1_loss_9: 0.4956 - dense_1_loss_10: 0.4841 - dense_1_loss_11: 0.4578 - dense_1_loss_12: 0.4387 - dense_1_loss_13: 0.4119 - dense_1_loss_14: 0.4026 - dense_1_loss_15: 0.4579 - dense_1_loss_16: 0.4448 - dense_1_loss_17: 0.4265 - dense_1_loss_18: 0.4421 - dense_1_loss_19: 0.4644 - dense_1_loss_20: 0.4591 - dense_1_loss_21: 0.4662 - dense_1_loss_22: 0.4745 - dense_1_loss_23: 0.4785 - dense_1_loss_24: 0.4559 - dense_1_loss_25: 0.4584 - dense_1_loss_26: 0.4769 - dense_1_loss_27: 0.4623 - dense_1_loss_28: 0.5322 - dense_1_loss_29: 0.4967 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.7167 - dense_1_acc_5: 0.8000 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s - loss: 20.6808 - dense_1_loss_1: 3.9634 - dense_1_loss_2: 2.6551 - dense_1_loss_3: 1.4972 - dense_1_loss_4: 1.0265 - dense_1_loss_5: 0.8827 - dense_1_loss_6: 0.6113 - dense_1_loss_7: 0.5353 - dense_1_loss_8: 0.5446 - dense_1_loss_9: 0.4773 - dense_1_loss_10: 0.4454 - dense_1_loss_11: 0.4310 - dense_1_loss_12: 0.4063 - dense_1_loss_13: 0.3762 - dense_1_loss_14: 0.3871 - dense_1_loss_15: 0.4113 - dense_1_loss_16: 0.4152 - dense_1_loss_17: 0.3941 - dense_1_loss_18: 0.4126 - dense_1_loss_19: 0.4276 - dense_1_loss_20: 0.4263 - dense_1_loss_21: 0.4300 - dense_1_loss_22: 0.4502 - dense_1_loss_23: 0.4236 - dense_1_loss_24: 0.4183 - dense_1_loss_25: 0.4166 - dense_1_loss_26: 0.4383 - dense_1_loss_27: 0.4247 - dense_1_loss_28: 0.4891 - dense_1_loss_29: 0.4635 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0500 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.8500 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 0.9833 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s - loss: 19.5758 - dense_1_loss_1: 3.9581 - dense_1_loss_2: 2.6106 - dense_1_loss_3: 1.4426 - dense_1_loss_4: 0.9709 - dense_1_loss_5: 0.8299 - dense_1_loss_6: 0.5574 - dense_1_loss_7: 0.4959 - dense_1_loss_8: 0.5032 - dense_1_loss_9: 0.4209 - dense_1_loss_10: 0.4108 - dense_1_loss_11: 0.3848 - dense_1_loss_12: 0.3694 - dense_1_loss_13: 0.3427 - dense_1_loss_14: 0.3440 - dense_1_loss_15: 0.3802 - dense_1_loss_16: 0.3714 - dense_1_loss_17: 0.3536 - dense_1_loss_18: 0.3829 - dense_1_loss_19: 0.3935 - dense_1_loss_20: 0.3858 - dense_1_loss_21: 0.3979 - dense_1_loss_22: 0.4163 - dense_1_loss_23: 0.3993 - dense_1_loss_24: 0.3832 - dense_1_loss_25: 0.3871 - dense_1_loss_26: 0.4064 - dense_1_loss_27: 0.3981 - dense_1_loss_28: 0.4548 - dense_1_loss_29: 0.4238 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.7833 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s - loss: 18.5977 - dense_1_loss_1: 3.9524 - dense_1_loss_2: 2.5678 - dense_1_loss_3: 1.3928 - dense_1_loss_4: 0.9118 - dense_1_loss_5: 0.7820 - dense_1_loss_6: 0.5111 - dense_1_loss_7: 0.4610 - dense_1_loss_8: 0.4596 - dense_1_loss_9: 0.3842 - dense_1_loss_10: 0.3839 - dense_1_loss_11: 0.3417 - dense_1_loss_12: 0.3411 - dense_1_loss_13: 0.3180 - dense_1_loss_14: 0.3052 - dense_1_loss_15: 0.3633 - dense_1_loss_16: 0.3430 - dense_1_loss_17: 0.3310 - dense_1_loss_18: 0.3507 - dense_1_loss_19: 0.3575 - dense_1_loss_20: 0.3664 - dense_1_loss_21: 0.3685 - dense_1_loss_22: 0.3696 - dense_1_loss_23: 0.3733 - dense_1_loss_24: 0.3559 - dense_1_loss_25: 0.3559 - dense_1_loss_26: 0.3754 - dense_1_loss_27: 0.3640 - dense_1_loss_28: 0.4245 - dense_1_loss_29: 0.3861 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8000 - dense_1_acc_5: 0.9167 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 17.6684 - dense_1_loss_1: 3.9470 - dense_1_loss_2: 2.5242 - dense_1_loss_3: 1.3462 - dense_1_loss_4: 0.8592 - dense_1_loss_5: 0.7353 - dense_1_loss_6: 0.4814 - dense_1_loss_7: 0.4214 - dense_1_loss_8: 0.4200 - dense_1_loss_9: 0.3622 - dense_1_loss_10: 0.3499 - dense_1_loss_11: 0.3203 - dense_1_loss_12: 0.3148 - dense_1_loss_13: 0.2904 - dense_1_loss_14: 0.2845 - dense_1_loss_15: 0.3260 - dense_1_loss_16: 0.3138 - dense_1_loss_17: 0.3035 - dense_1_loss_18: 0.3198 - dense_1_loss_19: 0.3286 - dense_1_loss_20: 0.3424 - dense_1_loss_21: 0.3381 - dense_1_loss_22: 0.3356 - dense_1_loss_23: 0.3346 - dense_1_loss_24: 0.3209 - dense_1_loss_25: 0.3313 - dense_1_loss_26: 0.3414 - dense_1_loss_27: 0.3281 - dense_1_loss_28: 0.3854 - dense_1_loss_29: 0.3619 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8333 - dense_1_acc_5: 0.9167 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s - loss: 16.8501 - dense_1_loss_1: 3.9408 - dense_1_loss_2: 2.4849 - dense_1_loss_3: 1.3012 - dense_1_loss_4: 0.8152 - dense_1_loss_5: 0.6892 - dense_1_loss_6: 0.4487 - dense_1_loss_7: 0.3873 - dense_1_loss_8: 0.3915 - dense_1_loss_9: 0.3348 - dense_1_loss_10: 0.3209 - dense_1_loss_11: 0.3022 - dense_1_loss_12: 0.2874 - dense_1_loss_13: 0.2687 - dense_1_loss_14: 0.2645 - dense_1_loss_15: 0.2941 - dense_1_loss_16: 0.2847 - dense_1_loss_17: 0.2707 - dense_1_loss_18: 0.2975 - dense_1_loss_19: 0.3124 - dense_1_loss_20: 0.3062 - dense_1_loss_21: 0.3059 - dense_1_loss_22: 0.3117 - dense_1_loss_23: 0.3138 - dense_1_loss_24: 0.2987 - dense_1_loss_25: 0.3018 - dense_1_loss_26: 0.3093 - dense_1_loss_27: 0.3065 - dense_1_loss_28: 0.3618 - dense_1_loss_29: 0.3376 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8333 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s - loss: 16.0731 - dense_1_loss_1: 3.9360 - dense_1_loss_2: 2.4427 - dense_1_loss_3: 1.2571 - dense_1_loss_4: 0.7650 - dense_1_loss_5: 0.6520 - dense_1_loss_6: 0.4166 - dense_1_loss_7: 0.3558 - dense_1_loss_8: 0.3636 - dense_1_loss_9: 0.3058 - dense_1_loss_10: 0.2970 - dense_1_loss_11: 0.2741 - dense_1_loss_12: 0.2637 - dense_1_loss_13: 0.2478 - dense_1_loss_14: 0.2427 - dense_1_loss_15: 0.2688 - dense_1_loss_16: 0.2646 - dense_1_loss_17: 0.2522 - dense_1_loss_18: 0.2716 - dense_1_loss_19: 0.2835 - dense_1_loss_20: 0.2830 - dense_1_loss_21: 0.2835 - dense_1_loss_22: 0.2939 - dense_1_loss_23: 0.2841 - dense_1_loss_24: 0.2714 - dense_1_loss_25: 0.2743 - dense_1_loss_26: 0.2908 - dense_1_loss_27: 0.2824 - dense_1_loss_28: 0.3367 - dense_1_loss_29: 0.3125 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8833 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s - loss: 15.3671 - dense_1_loss_1: 3.9304 - dense_1_loss_2: 2.4040 - dense_1_loss_3: 1.2153 - dense_1_loss_4: 0.7207 - dense_1_loss_5: 0.6100 - dense_1_loss_6: 0.3861 - dense_1_loss_7: 0.3282 - dense_1_loss_8: 0.3351 - dense_1_loss_9: 0.2837 - dense_1_loss_10: 0.2742 - dense_1_loss_11: 0.2513 - dense_1_loss_12: 0.2437 - dense_1_loss_13: 0.2283 - dense_1_loss_14: 0.2213 - dense_1_loss_15: 0.2476 - dense_1_loss_16: 0.2481 - dense_1_loss_17: 0.2346 - dense_1_loss_18: 0.2505 - dense_1_loss_19: 0.2631 - dense_1_loss_20: 0.2604 - dense_1_loss_21: 0.2615 - dense_1_loss_22: 0.2697 - dense_1_loss_23: 0.2652 - dense_1_loss_24: 0.2496 - dense_1_loss_25: 0.2499 - dense_1_loss_26: 0.2677 - dense_1_loss_27: 0.2634 - dense_1_loss_28: 0.3149 - dense_1_loss_29: 0.2890 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.8833 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s - loss: 14.6983 - dense_1_loss_1: 3.9260 - dense_1_loss_2: 2.3653 - dense_1_loss_3: 1.1748 - dense_1_loss_4: 0.6846 - dense_1_loss_5: 0.5702 - dense_1_loss_6: 0.3565 - dense_1_loss_7: 0.3002 - dense_1_loss_8: 0.3036 - dense_1_loss_9: 0.2644 - dense_1_loss_10: 0.2502 - dense_1_loss_11: 0.2335 - dense_1_loss_12: 0.2257 - dense_1_loss_13: 0.2092 - dense_1_loss_14: 0.2023 - dense_1_loss_15: 0.2280 - dense_1_loss_16: 0.2258 - dense_1_loss_17: 0.2128 - dense_1_loss_18: 0.2329 - dense_1_loss_19: 0.2452 - dense_1_loss_20: 0.2361 - dense_1_loss_21: 0.2417 - dense_1_loss_22: 0.2458 - dense_1_loss_23: 0.2470 - dense_1_loss_24: 0.2328 - dense_1_loss_25: 0.2307 - dense_1_loss_26: 0.2444 - dense_1_loss_27: 0.2470 - dense_1_loss_28: 0.2908 - dense_1_loss_29: 0.2710 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9000 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s - loss: 14.0972 - dense_1_loss_1: 3.9205 - dense_1_loss_2: 2.3275 - dense_1_loss_3: 1.1374 - dense_1_loss_4: 0.6463 - dense_1_loss_5: 0.5350 - dense_1_loss_6: 0.3357 - dense_1_loss_7: 0.2803 - dense_1_loss_8: 0.2841 - dense_1_loss_9: 0.2434 - dense_1_loss_10: 0.2317 - dense_1_loss_11: 0.2164 - dense_1_loss_12: 0.2092 - dense_1_loss_13: 0.1941 - dense_1_loss_14: 0.1843 - dense_1_loss_15: 0.2130 - dense_1_loss_16: 0.2085 - dense_1_loss_17: 0.1949 - dense_1_loss_18: 0.2175 - dense_1_loss_19: 0.2250 - dense_1_loss_20: 0.2184 - dense_1_loss_21: 0.2247 - dense_1_loss_22: 0.2251 - dense_1_loss_23: 0.2233 - dense_1_loss_24: 0.2151 - dense_1_loss_25: 0.2171 - dense_1_loss_26: 0.2211 - dense_1_loss_27: 0.2292 - dense_1_loss_28: 0.2642 - dense_1_loss_29: 0.2543 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s - loss: 13.5453 - dense_1_loss_1: 3.9157 - dense_1_loss_2: 2.2912 - dense_1_loss_3: 1.1014 - dense_1_loss_4: 0.6089 - dense_1_loss_5: 0.5029 - dense_1_loss_6: 0.3127 - dense_1_loss_7: 0.2582 - dense_1_loss_8: 0.2629 - dense_1_loss_9: 0.2254 - dense_1_loss_10: 0.2158 - dense_1_loss_11: 0.1986 - dense_1_loss_12: 0.1933 - dense_1_loss_13: 0.1800 - dense_1_loss_14: 0.1698 - dense_1_loss_15: 0.1975 - dense_1_loss_16: 0.1890 - dense_1_loss_17: 0.1839 - dense_1_loss_18: 0.2005 - dense_1_loss_19: 0.2053 - dense_1_loss_20: 0.2053 - dense_1_loss_21: 0.2089 - dense_1_loss_22: 0.2090 - dense_1_loss_23: 0.2050 - dense_1_loss_24: 0.1977 - dense_1_loss_25: 0.2050 - dense_1_loss_26: 0.2053 - dense_1_loss_27: 0.2132 - dense_1_loss_28: 0.2441 - dense_1_loss_29: 0.2388 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s - loss: 13.0245 - dense_1_loss_1: 3.9110 - dense_1_loss_2: 2.2556 - dense_1_loss_3: 1.0687 - dense_1_loss_4: 0.5769 - dense_1_loss_5: 0.4732 - dense_1_loss_6: 0.2900 - dense_1_loss_7: 0.2371 - dense_1_loss_8: 0.2396 - dense_1_loss_9: 0.2097 - dense_1_loss_10: 0.1992 - dense_1_loss_11: 0.1859 - dense_1_loss_12: 0.1790 - dense_1_loss_13: 0.1645 - dense_1_loss_14: 0.1589 - dense_1_loss_15: 0.1785 - dense_1_loss_16: 0.1737 - dense_1_loss_17: 0.1691 - dense_1_loss_18: 0.1851 - dense_1_loss_19: 0.1907 - dense_1_loss_20: 0.1908 - dense_1_loss_21: 0.1901 - dense_1_loss_22: 0.1928 - dense_1_loss_23: 0.1944 - dense_1_loss_24: 0.1823 - dense_1_loss_25: 0.1868 - dense_1_loss_26: 0.1938 - dense_1_loss_27: 0.1969 - dense_1_loss_28: 0.2329 - dense_1_loss_29: 0.2174 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s - loss: 12.5563 - dense_1_loss_1: 3.9064 - dense_1_loss_2: 2.2213 - dense_1_loss_3: 1.0346 - dense_1_loss_4: 0.5472 - dense_1_loss_5: 0.4467 - dense_1_loss_6: 0.2732 - dense_1_loss_7: 0.2219 - dense_1_loss_8: 0.2247 - dense_1_loss_9: 0.1959 - dense_1_loss_10: 0.1839 - dense_1_loss_11: 0.1755 - dense_1_loss_12: 0.1663 - dense_1_loss_13: 0.1519 - dense_1_loss_14: 0.1488 - dense_1_loss_15: 0.1648 - dense_1_loss_16: 0.1634 - dense_1_loss_17: 0.1550 - dense_1_loss_18: 0.1689 - dense_1_loss_19: 0.1786 - dense_1_loss_20: 0.1773 - dense_1_loss_21: 0.1759 - dense_1_loss_22: 0.1793 - dense_1_loss_23: 0.1766 - dense_1_loss_24: 0.1687 - dense_1_loss_25: 0.1711 - dense_1_loss_26: 0.1785 - dense_1_loss_27: 0.1822 - dense_1_loss_28: 0.2141 - dense_1_loss_29: 0.2035 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s - loss: 12.1219 - dense_1_loss_1: 3.9017 - dense_1_loss_2: 2.1875 - dense_1_loss_3: 1.0017 - dense_1_loss_4: 0.5181 - dense_1_loss_5: 0.4196 - dense_1_loss_6: 0.2563 - dense_1_loss_7: 0.2067 - dense_1_loss_8: 0.2094 - dense_1_loss_9: 0.1813 - dense_1_loss_10: 0.1712 - dense_1_loss_11: 0.1611 - dense_1_loss_12: 0.1538 - dense_1_loss_13: 0.1417 - dense_1_loss_14: 0.1377 - dense_1_loss_15: 0.1535 - dense_1_loss_16: 0.1510 - dense_1_loss_17: 0.1432 - dense_1_loss_18: 0.1583 - dense_1_loss_19: 0.1663 - dense_1_loss_20: 0.1635 - dense_1_loss_21: 0.1631 - dense_1_loss_22: 0.1666 - dense_1_loss_23: 0.1640 - dense_1_loss_24: 0.1580 - dense_1_loss_25: 0.1594 - dense_1_loss_26: 0.1648 - dense_1_loss_27: 0.1696 - dense_1_loss_28: 0.1997 - dense_1_loss_29: 0.1934 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 11.7219 - dense_1_loss_1: 3.8975 - dense_1_loss_2: 2.1535 - dense_1_loss_3: 0.9725 - dense_1_loss_4: 0.4906 - dense_1_loss_5: 0.3942 - dense_1_loss_6: 0.2385 - dense_1_loss_7: 0.1925 - dense_1_loss_8: 0.1927 - dense_1_loss_9: 0.1709 - dense_1_loss_10: 0.1594 - dense_1_loss_11: 0.1494 - dense_1_loss_12: 0.1419 - dense_1_loss_13: 0.1330 - dense_1_loss_14: 0.1279 - dense_1_loss_15: 0.1437 - dense_1_loss_16: 0.1382 - dense_1_loss_17: 0.1335 - dense_1_loss_18: 0.1495 - dense_1_loss_19: 0.1535 - dense_1_loss_20: 0.1524 - dense_1_loss_21: 0.1522 - dense_1_loss_22: 0.1531 - dense_1_loss_23: 0.1552 - dense_1_loss_24: 0.1470 - dense_1_loss_25: 0.1495 - dense_1_loss_26: 0.1528 - dense_1_loss_27: 0.1578 - dense_1_loss_28: 0.1863 - dense_1_loss_29: 0.1828 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s - loss: 11.3593 - dense_1_loss_1: 3.8933 - dense_1_loss_2: 2.1222 - dense_1_loss_3: 0.9430 - dense_1_loss_4: 0.4657 - dense_1_loss_5: 0.3708 - dense_1_loss_6: 0.2237 - dense_1_loss_7: 0.1787 - dense_1_loss_8: 0.1795 - dense_1_loss_9: 0.1608 - dense_1_loss_10: 0.1488 - dense_1_loss_11: 0.1399 - dense_1_loss_12: 0.1327 - dense_1_loss_13: 0.1240 - dense_1_loss_14: 0.1199 - dense_1_loss_15: 0.1342 - dense_1_loss_16: 0.1287 - dense_1_loss_17: 0.1250 - dense_1_loss_18: 0.1407 - dense_1_loss_19: 0.1423 - dense_1_loss_20: 0.1436 - dense_1_loss_21: 0.1431 - dense_1_loss_22: 0.1419 - dense_1_loss_23: 0.1447 - dense_1_loss_24: 0.1370 - dense_1_loss_25: 0.1406 - dense_1_loss_26: 0.1417 - dense_1_loss_27: 0.1495 - dense_1_loss_28: 0.1724 - dense_1_loss_29: 0.1708 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s - loss: 11.0275 - dense_1_loss_1: 3.8887 - dense_1_loss_2: 2.0909 - dense_1_loss_3: 0.9166 - dense_1_loss_4: 0.4448 - dense_1_loss_5: 0.3512 - dense_1_loss_6: 0.2108 - dense_1_loss_7: 0.1683 - dense_1_loss_8: 0.1686 - dense_1_loss_9: 0.1505 - dense_1_loss_10: 0.1380 - dense_1_loss_11: 0.1316 - dense_1_loss_12: 0.1246 - dense_1_loss_13: 0.1155 - dense_1_loss_14: 0.1121 - dense_1_loss_15: 0.1250 - dense_1_loss_16: 0.1221 - dense_1_loss_17: 0.1153 - dense_1_loss_18: 0.1305 - dense_1_loss_19: 0.1326 - dense_1_loss_20: 0.1344 - dense_1_loss_21: 0.1341 - dense_1_loss_22: 0.1340 - dense_1_loss_23: 0.1325 - dense_1_loss_24: 0.1284 - dense_1_loss_25: 0.1314 - dense_1_loss_26: 0.1328 - dense_1_loss_27: 0.1407 - dense_1_loss_28: 0.1612 - dense_1_loss_29: 0.1603 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s - loss: 10.7173 - dense_1_loss_1: 3.8845 - dense_1_loss_2: 2.0613 - dense_1_loss_3: 0.8902 - dense_1_loss_4: 0.4237 - dense_1_loss_5: 0.3306 - dense_1_loss_6: 0.1976 - dense_1_loss_7: 0.1582 - dense_1_loss_8: 0.1581 - dense_1_loss_9: 0.1407 - dense_1_loss_10: 0.1289 - dense_1_loss_11: 0.1232 - dense_1_loss_12: 0.1176 - dense_1_loss_13: 0.1068 - dense_1_loss_14: 0.1051 - dense_1_loss_15: 0.1170 - dense_1_loss_16: 0.1139 - dense_1_loss_17: 0.1073 - dense_1_loss_18: 0.1213 - dense_1_loss_19: 0.1256 - dense_1_loss_20: 0.1246 - dense_1_loss_21: 0.1250 - dense_1_loss_22: 0.1273 - dense_1_loss_23: 0.1234 - dense_1_loss_24: 0.1206 - dense_1_loss_25: 0.1230 - dense_1_loss_26: 0.1256 - dense_1_loss_27: 0.1326 - dense_1_loss_28: 0.1512 - dense_1_loss_29: 0.1524 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s - loss: 10.4318 - dense_1_loss_1: 3.8804 - dense_1_loss_2: 2.0304 - dense_1_loss_3: 0.8656 - dense_1_loss_4: 0.4038 - dense_1_loss_5: 0.3137 - dense_1_loss_6: 0.1863 - dense_1_loss_7: 0.1492 - dense_1_loss_8: 0.1500 - dense_1_loss_9: 0.1324 - dense_1_loss_10: 0.1215 - dense_1_loss_11: 0.1152 - dense_1_loss_12: 0.1105 - dense_1_loss_13: 0.1005 - dense_1_loss_14: 0.0990 - dense_1_loss_15: 0.1100 - dense_1_loss_16: 0.1057 - dense_1_loss_17: 0.1004 - dense_1_loss_18: 0.1144 - dense_1_loss_19: 0.1185 - dense_1_loss_20: 0.1161 - dense_1_loss_21: 0.1166 - dense_1_loss_22: 0.1195 - dense_1_loss_23: 0.1163 - dense_1_loss_24: 0.1133 - dense_1_loss_25: 0.1157 - dense_1_loss_26: 0.1175 - dense_1_loss_27: 0.1246 - dense_1_loss_28: 0.1414 - dense_1_loss_29: 0.1432 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s - loss: 10.1622 - dense_1_loss_1: 3.8768 - dense_1_loss_2: 2.0029 - dense_1_loss_3: 0.8407 - dense_1_loss_4: 0.3840 - dense_1_loss_5: 0.2952 - dense_1_loss_6: 0.1750 - dense_1_loss_7: 0.1406 - dense_1_loss_8: 0.1400 - dense_1_loss_9: 0.1255 - dense_1_loss_10: 0.1152 - dense_1_loss_11: 0.1080 - dense_1_loss_12: 0.1039 - dense_1_loss_13: 0.0947 - dense_1_loss_14: 0.0933 - dense_1_loss_15: 0.1035 - dense_1_loss_16: 0.0990 - dense_1_loss_17: 0.0947 - dense_1_loss_18: 0.1078 - dense_1_loss_19: 0.1109 - dense_1_loss_20: 0.1099 - dense_1_loss_21: 0.1087 - dense_1_loss_22: 0.1122 - dense_1_loss_23: 0.1096 - dense_1_loss_24: 0.1062 - dense_1_loss_25: 0.1088 - dense_1_loss_26: 0.1098 - dense_1_loss_27: 0.1177 - dense_1_loss_28: 0.1327 - dense_1_loss_29: 0.1350 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8167 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00    \n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s - loss: 9.9192 - dense_1_loss_1: 3.8728 - dense_1_loss_2: 1.9743 - dense_1_loss_3: 0.8187 - dense_1_loss_4: 0.3671 - dense_1_loss_5: 0.2799 - dense_1_loss_6: 0.1671 - dense_1_loss_7: 0.1322 - dense_1_loss_8: 0.1328 - dense_1_loss_9: 0.1185 - dense_1_loss_10: 0.1088 - dense_1_loss_11: 0.1020 - dense_1_loss_12: 0.0981 - dense_1_loss_13: 0.0896 - dense_1_loss_14: 0.0882 - dense_1_loss_15: 0.0979 - dense_1_loss_16: 0.0934 - dense_1_loss_17: 0.0891 - dense_1_loss_18: 0.1014 - dense_1_loss_19: 0.1035 - dense_1_loss_20: 0.1042 - dense_1_loss_21: 0.1034 - dense_1_loss_22: 0.1042 - dense_1_loss_23: 0.1023 - dense_1_loss_24: 0.1003 - dense_1_loss_25: 0.1022 - dense_1_loss_26: 0.1030 - dense_1_loss_27: 0.1116 - dense_1_loss_28: 0.1251 - dense_1_loss_29: 0.1276 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8167 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00      \n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s - loss: 9.6904 - dense_1_loss_1: 3.8687 - dense_1_loss_2: 1.9471 - dense_1_loss_3: 0.7982 - dense_1_loss_4: 0.3506 - dense_1_loss_5: 0.2649 - dense_1_loss_6: 0.1593 - dense_1_loss_7: 0.1246 - dense_1_loss_8: 0.1260 - dense_1_loss_9: 0.1113 - dense_1_loss_10: 0.1029 - dense_1_loss_11: 0.0960 - dense_1_loss_12: 0.0926 - dense_1_loss_13: 0.0842 - dense_1_loss_14: 0.0827 - dense_1_loss_15: 0.0924 - dense_1_loss_16: 0.0883 - dense_1_loss_17: 0.0836 - dense_1_loss_18: 0.0952 - dense_1_loss_19: 0.0976 - dense_1_loss_20: 0.0982 - dense_1_loss_21: 0.0977 - dense_1_loss_22: 0.0986 - dense_1_loss_23: 0.0967 - dense_1_loss_24: 0.0948 - dense_1_loss_25: 0.0960 - dense_1_loss_26: 0.0978 - dense_1_loss_27: 0.1053 - dense_1_loss_28: 0.1182 - dense_1_loss_29: 0.1210 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8167 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00      \n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s - loss: 9.4753 - dense_1_loss_1: 3.8652 - dense_1_loss_2: 1.9216 - dense_1_loss_3: 0.7767 - dense_1_loss_4: 0.3359 - dense_1_loss_5: 0.2507 - dense_1_loss_6: 0.1508 - dense_1_loss_7: 0.1181 - dense_1_loss_8: 0.1190 - dense_1_loss_9: 0.1049 - dense_1_loss_10: 0.0971 - dense_1_loss_11: 0.0906 - dense_1_loss_12: 0.0879 - dense_1_loss_13: 0.0793 - dense_1_loss_14: 0.0782 - dense_1_loss_15: 0.0872 - dense_1_loss_16: 0.0835 - dense_1_loss_17: 0.0791 - dense_1_loss_18: 0.0896 - dense_1_loss_19: 0.0925 - dense_1_loss_20: 0.0926 - dense_1_loss_21: 0.0923 - dense_1_loss_22: 0.0932 - dense_1_loss_23: 0.0913 - dense_1_loss_24: 0.0894 - dense_1_loss_25: 0.0909 - dense_1_loss_26: 0.0925 - dense_1_loss_27: 0.0996 - dense_1_loss_28: 0.1112 - dense_1_loss_29: 0.1145 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8500 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s - loss: 9.2775 - dense_1_loss_1: 3.8615 - dense_1_loss_2: 1.8955 - dense_1_loss_3: 0.7571 - dense_1_loss_4: 0.3217 - dense_1_loss_5: 0.2364 - dense_1_loss_6: 0.1435 - dense_1_loss_7: 0.1122 - dense_1_loss_8: 0.1130 - dense_1_loss_9: 0.0992 - dense_1_loss_10: 0.0917 - dense_1_loss_11: 0.0858 - dense_1_loss_12: 0.0832 - dense_1_loss_13: 0.0750 - dense_1_loss_14: 0.0745 - dense_1_loss_15: 0.0825 - dense_1_loss_16: 0.0792 - dense_1_loss_17: 0.0752 - dense_1_loss_18: 0.0848 - dense_1_loss_19: 0.0877 - dense_1_loss_20: 0.0878 - dense_1_loss_21: 0.0872 - dense_1_loss_22: 0.0887 - dense_1_loss_23: 0.0861 - dense_1_loss_24: 0.0842 - dense_1_loss_25: 0.0867 - dense_1_loss_26: 0.0878 - dense_1_loss_27: 0.0942 - dense_1_loss_28: 0.1053 - dense_1_loss_29: 0.1096 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 9.0948 - dense_1_loss_1: 3.8577 - dense_1_loss_2: 1.8707 - dense_1_loss_3: 0.7387 - dense_1_loss_4: 0.3069 - dense_1_loss_5: 0.2250 - dense_1_loss_6: 0.1370 - dense_1_loss_7: 0.1069 - dense_1_loss_8: 0.1078 - dense_1_loss_9: 0.0950 - dense_1_loss_10: 0.0872 - dense_1_loss_11: 0.0816 - dense_1_loss_12: 0.0787 - dense_1_loss_13: 0.0714 - dense_1_loss_14: 0.0713 - dense_1_loss_15: 0.0779 - dense_1_loss_16: 0.0753 - dense_1_loss_17: 0.0714 - dense_1_loss_18: 0.0807 - dense_1_loss_19: 0.0829 - dense_1_loss_20: 0.0834 - dense_1_loss_21: 0.0826 - dense_1_loss_22: 0.0841 - dense_1_loss_23: 0.0816 - dense_1_loss_24: 0.0797 - dense_1_loss_25: 0.0826 - dense_1_loss_26: 0.0829 - dense_1_loss_27: 0.0898 - dense_1_loss_28: 0.0994 - dense_1_loss_29: 0.1042 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s - loss: 8.9266 - dense_1_loss_1: 3.8542 - dense_1_loss_2: 1.8460 - dense_1_loss_3: 0.7212 - dense_1_loss_4: 0.2957 - dense_1_loss_5: 0.2141 - dense_1_loss_6: 0.1305 - dense_1_loss_7: 0.1020 - dense_1_loss_8: 0.1024 - dense_1_loss_9: 0.0904 - dense_1_loss_10: 0.0828 - dense_1_loss_11: 0.0778 - dense_1_loss_12: 0.0746 - dense_1_loss_13: 0.0681 - dense_1_loss_14: 0.0676 - dense_1_loss_15: 0.0741 - dense_1_loss_16: 0.0717 - dense_1_loss_17: 0.0675 - dense_1_loss_18: 0.0771 - dense_1_loss_19: 0.0790 - dense_1_loss_20: 0.0791 - dense_1_loss_21: 0.0784 - dense_1_loss_22: 0.0800 - dense_1_loss_23: 0.0779 - dense_1_loss_24: 0.0761 - dense_1_loss_25: 0.0786 - dense_1_loss_26: 0.0788 - dense_1_loss_27: 0.0861 - dense_1_loss_28: 0.0952 - dense_1_loss_29: 0.0998 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s - loss: 8.7634 - dense_1_loss_1: 3.8507 - dense_1_loss_2: 1.8224 - dense_1_loss_3: 0.7033 - dense_1_loss_4: 0.2835 - dense_1_loss_5: 0.2034 - dense_1_loss_6: 0.1245 - dense_1_loss_7: 0.0977 - dense_1_loss_8: 0.0975 - dense_1_loss_9: 0.0857 - dense_1_loss_10: 0.0785 - dense_1_loss_11: 0.0741 - dense_1_loss_12: 0.0708 - dense_1_loss_13: 0.0649 - dense_1_loss_14: 0.0643 - dense_1_loss_15: 0.0709 - dense_1_loss_16: 0.0683 - dense_1_loss_17: 0.0638 - dense_1_loss_18: 0.0734 - dense_1_loss_19: 0.0752 - dense_1_loss_20: 0.0750 - dense_1_loss_21: 0.0747 - dense_1_loss_22: 0.0762 - dense_1_loss_23: 0.0741 - dense_1_loss_24: 0.0724 - dense_1_loss_25: 0.0750 - dense_1_loss_26: 0.0751 - dense_1_loss_27: 0.0818 - dense_1_loss_28: 0.0909 - dense_1_loss_29: 0.0956 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s - loss: 8.6111 - dense_1_loss_1: 3.8472 - dense_1_loss_2: 1.8001 - dense_1_loss_3: 0.6864 - dense_1_loss_4: 0.2730 - dense_1_loss_5: 0.1927 - dense_1_loss_6: 0.1191 - dense_1_loss_7: 0.0934 - dense_1_loss_8: 0.0929 - dense_1_loss_9: 0.0819 - dense_1_loss_10: 0.0749 - dense_1_loss_11: 0.0707 - dense_1_loss_12: 0.0675 - dense_1_loss_13: 0.0620 - dense_1_loss_14: 0.0612 - dense_1_loss_15: 0.0677 - dense_1_loss_16: 0.0653 - dense_1_loss_17: 0.0607 - dense_1_loss_18: 0.0700 - dense_1_loss_19: 0.0715 - dense_1_loss_20: 0.0715 - dense_1_loss_21: 0.0711 - dense_1_loss_22: 0.0725 - dense_1_loss_23: 0.0703 - dense_1_loss_24: 0.0692 - dense_1_loss_25: 0.0715 - dense_1_loss_26: 0.0718 - dense_1_loss_27: 0.0779 - dense_1_loss_28: 0.0866 - dense_1_loss_29: 0.0907 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s - loss: 8.4710 - dense_1_loss_1: 3.8440 - dense_1_loss_2: 1.7775 - dense_1_loss_3: 0.6712 - dense_1_loss_4: 0.2630 - dense_1_loss_5: 0.1840 - dense_1_loss_6: 0.1142 - dense_1_loss_7: 0.0894 - dense_1_loss_8: 0.0889 - dense_1_loss_9: 0.0786 - dense_1_loss_10: 0.0716 - dense_1_loss_11: 0.0677 - dense_1_loss_12: 0.0645 - dense_1_loss_13: 0.0593 - dense_1_loss_14: 0.0587 - dense_1_loss_15: 0.0647 - dense_1_loss_16: 0.0626 - dense_1_loss_17: 0.0582 - dense_1_loss_18: 0.0668 - dense_1_loss_19: 0.0683 - dense_1_loss_20: 0.0684 - dense_1_loss_21: 0.0679 - dense_1_loss_22: 0.0692 - dense_1_loss_23: 0.0665 - dense_1_loss_24: 0.0659 - dense_1_loss_25: 0.0685 - dense_1_loss_26: 0.0681 - dense_1_loss_27: 0.0745 - dense_1_loss_28: 0.0823 - dense_1_loss_29: 0.0867 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s - loss: 8.3359 - dense_1_loss_1: 3.8406 - dense_1_loss_2: 1.7557 - dense_1_loss_3: 0.6554 - dense_1_loss_4: 0.2527 - dense_1_loss_5: 0.1752 - dense_1_loss_6: 0.1094 - dense_1_loss_7: 0.0858 - dense_1_loss_8: 0.0851 - dense_1_loss_9: 0.0752 - dense_1_loss_10: 0.0683 - dense_1_loss_11: 0.0647 - dense_1_loss_12: 0.0616 - dense_1_loss_13: 0.0568 - dense_1_loss_14: 0.0565 - dense_1_loss_15: 0.0619 - dense_1_loss_16: 0.0598 - dense_1_loss_17: 0.0557 - dense_1_loss_18: 0.0638 - dense_1_loss_19: 0.0653 - dense_1_loss_20: 0.0654 - dense_1_loss_21: 0.0648 - dense_1_loss_22: 0.0662 - dense_1_loss_23: 0.0635 - dense_1_loss_24: 0.0628 - dense_1_loss_25: 0.0657 - dense_1_loss_26: 0.0647 - dense_1_loss_27: 0.0719 - dense_1_loss_28: 0.0780 - dense_1_loss_29: 0.0832 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s - loss: 8.2123 - dense_1_loss_1: 3.8372 - dense_1_loss_2: 1.7341 - dense_1_loss_3: 0.6413 - dense_1_loss_4: 0.2438 - dense_1_loss_5: 0.1684 - dense_1_loss_6: 0.1053 - dense_1_loss_7: 0.0826 - dense_1_loss_8: 0.0818 - dense_1_loss_9: 0.0723 - dense_1_loss_10: 0.0654 - dense_1_loss_11: 0.0619 - dense_1_loss_12: 0.0592 - dense_1_loss_13: 0.0545 - dense_1_loss_14: 0.0541 - dense_1_loss_15: 0.0595 - dense_1_loss_16: 0.0571 - dense_1_loss_17: 0.0534 - dense_1_loss_18: 0.0611 - dense_1_loss_19: 0.0626 - dense_1_loss_20: 0.0625 - dense_1_loss_21: 0.0617 - dense_1_loss_22: 0.0635 - dense_1_loss_23: 0.0609 - dense_1_loss_24: 0.0601 - dense_1_loss_25: 0.0628 - dense_1_loss_26: 0.0622 - dense_1_loss_27: 0.0688 - dense_1_loss_28: 0.0748 - dense_1_loss_29: 0.0794 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s - loss: 8.0939 - dense_1_loss_1: 3.8339 - dense_1_loss_2: 1.7133 - dense_1_loss_3: 0.6270 - dense_1_loss_4: 0.2355 - dense_1_loss_5: 0.1608 - dense_1_loss_6: 0.1015 - dense_1_loss_7: 0.0792 - dense_1_loss_8: 0.0784 - dense_1_loss_9: 0.0692 - dense_1_loss_10: 0.0626 - dense_1_loss_11: 0.0594 - dense_1_loss_12: 0.0568 - dense_1_loss_13: 0.0521 - dense_1_loss_14: 0.0518 - dense_1_loss_15: 0.0573 - dense_1_loss_16: 0.0544 - dense_1_loss_17: 0.0511 - dense_1_loss_18: 0.0585 - dense_1_loss_19: 0.0601 - dense_1_loss_20: 0.0599 - dense_1_loss_21: 0.0591 - dense_1_loss_22: 0.0611 - dense_1_loss_23: 0.0586 - dense_1_loss_24: 0.0576 - dense_1_loss_25: 0.0600 - dense_1_loss_26: 0.0600 - dense_1_loss_27: 0.0658 - dense_1_loss_28: 0.0722 - dense_1_loss_29: 0.0765 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s - loss: 7.9812 - dense_1_loss_1: 3.8306 - dense_1_loss_2: 1.6935 - dense_1_loss_3: 0.6141 - dense_1_loss_4: 0.2266 - dense_1_loss_5: 0.1532 - dense_1_loss_6: 0.0975 - dense_1_loss_7: 0.0762 - dense_1_loss_8: 0.0750 - dense_1_loss_9: 0.0664 - dense_1_loss_10: 0.0601 - dense_1_loss_11: 0.0569 - dense_1_loss_12: 0.0545 - dense_1_loss_13: 0.0502 - dense_1_loss_14: 0.0496 - dense_1_loss_15: 0.0552 - dense_1_loss_16: 0.0523 - dense_1_loss_17: 0.0489 - dense_1_loss_18: 0.0564 - dense_1_loss_19: 0.0576 - dense_1_loss_20: 0.0573 - dense_1_loss_21: 0.0568 - dense_1_loss_22: 0.0586 - dense_1_loss_23: 0.0565 - dense_1_loss_24: 0.0554 - dense_1_loss_25: 0.0577 - dense_1_loss_26: 0.0574 - dense_1_loss_27: 0.0634 - dense_1_loss_28: 0.0695 - dense_1_loss_29: 0.0738 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s - loss: 7.8745 - dense_1_loss_1: 3.8275 - dense_1_loss_2: 1.6733 - dense_1_loss_3: 0.6004 - dense_1_loss_4: 0.2193 - dense_1_loss_5: 0.1466 - dense_1_loss_6: 0.0937 - dense_1_loss_7: 0.0735 - dense_1_loss_8: 0.0721 - dense_1_loss_9: 0.0640 - dense_1_loss_10: 0.0577 - dense_1_loss_11: 0.0549 - dense_1_loss_12: 0.0524 - dense_1_loss_13: 0.0482 - dense_1_loss_14: 0.0478 - dense_1_loss_15: 0.0530 - dense_1_loss_16: 0.0505 - dense_1_loss_17: 0.0469 - dense_1_loss_18: 0.0543 - dense_1_loss_19: 0.0554 - dense_1_loss_20: 0.0550 - dense_1_loss_21: 0.0546 - dense_1_loss_22: 0.0562 - dense_1_loss_23: 0.0540 - dense_1_loss_24: 0.0534 - dense_1_loss_25: 0.0554 - dense_1_loss_26: 0.0551 - dense_1_loss_27: 0.0611 - dense_1_loss_28: 0.0671 - dense_1_loss_29: 0.0710 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 7.7736 - dense_1_loss_1: 3.8243 - dense_1_loss_2: 1.6548 - dense_1_loss_3: 0.5880 - dense_1_loss_4: 0.2112 - dense_1_loss_5: 0.1407 - dense_1_loss_6: 0.0904 - dense_1_loss_7: 0.0710 - dense_1_loss_8: 0.0695 - dense_1_loss_9: 0.0616 - dense_1_loss_10: 0.0556 - dense_1_loss_11: 0.0530 - dense_1_loss_12: 0.0505 - dense_1_loss_13: 0.0465 - dense_1_loss_14: 0.0461 - dense_1_loss_15: 0.0510 - dense_1_loss_16: 0.0489 - dense_1_loss_17: 0.0451 - dense_1_loss_18: 0.0521 - dense_1_loss_19: 0.0531 - dense_1_loss_20: 0.0529 - dense_1_loss_21: 0.0526 - dense_1_loss_22: 0.0540 - dense_1_loss_23: 0.0518 - dense_1_loss_24: 0.0513 - dense_1_loss_25: 0.0534 - dense_1_loss_26: 0.0528 - dense_1_loss_27: 0.0587 - dense_1_loss_28: 0.0645 - dense_1_loss_29: 0.0681 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s - loss: 7.6779 - dense_1_loss_1: 3.8214 - dense_1_loss_2: 1.6356 - dense_1_loss_3: 0.5758 - dense_1_loss_4: 0.2050 - dense_1_loss_5: 0.1353 - dense_1_loss_6: 0.0873 - dense_1_loss_7: 0.0686 - dense_1_loss_8: 0.0670 - dense_1_loss_9: 0.0595 - dense_1_loss_10: 0.0534 - dense_1_loss_11: 0.0512 - dense_1_loss_12: 0.0486 - dense_1_loss_13: 0.0448 - dense_1_loss_14: 0.0444 - dense_1_loss_15: 0.0491 - dense_1_loss_16: 0.0473 - dense_1_loss_17: 0.0435 - dense_1_loss_18: 0.0501 - dense_1_loss_19: 0.0510 - dense_1_loss_20: 0.0510 - dense_1_loss_21: 0.0507 - dense_1_loss_22: 0.0520 - dense_1_loss_23: 0.0496 - dense_1_loss_24: 0.0496 - dense_1_loss_25: 0.0515 - dense_1_loss_26: 0.0507 - dense_1_loss_27: 0.0565 - dense_1_loss_28: 0.0621 - dense_1_loss_29: 0.0652 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s - loss: 7.5881 - dense_1_loss_1: 3.8181 - dense_1_loss_2: 1.6177 - dense_1_loss_3: 0.5646 - dense_1_loss_4: 0.1986 - dense_1_loss_5: 0.1304 - dense_1_loss_6: 0.0843 - dense_1_loss_7: 0.0662 - dense_1_loss_8: 0.0647 - dense_1_loss_9: 0.0573 - dense_1_loss_10: 0.0515 - dense_1_loss_11: 0.0494 - dense_1_loss_12: 0.0468 - dense_1_loss_13: 0.0432 - dense_1_loss_14: 0.0427 - dense_1_loss_15: 0.0476 - dense_1_loss_16: 0.0456 - dense_1_loss_17: 0.0420 - dense_1_loss_18: 0.0484 - dense_1_loss_19: 0.0494 - dense_1_loss_20: 0.0490 - dense_1_loss_21: 0.0487 - dense_1_loss_22: 0.0501 - dense_1_loss_23: 0.0480 - dense_1_loss_24: 0.0479 - dense_1_loss_25: 0.0496 - dense_1_loss_26: 0.0489 - dense_1_loss_27: 0.0546 - dense_1_loss_28: 0.0599 - dense_1_loss_29: 0.0627 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s - loss: 7.4988 - dense_1_loss_1: 3.8149 - dense_1_loss_2: 1.6000 - dense_1_loss_3: 0.5530 - dense_1_loss_4: 0.1912 - dense_1_loss_5: 0.1253 - dense_1_loss_6: 0.0813 - dense_1_loss_7: 0.0639 - dense_1_loss_8: 0.0625 - dense_1_loss_9: 0.0552 - dense_1_loss_10: 0.0497 - dense_1_loss_11: 0.0476 - dense_1_loss_12: 0.0451 - dense_1_loss_13: 0.0417 - dense_1_loss_14: 0.0412 - dense_1_loss_15: 0.0460 - dense_1_loss_16: 0.0438 - dense_1_loss_17: 0.0405 - dense_1_loss_18: 0.0467 - dense_1_loss_19: 0.0476 - dense_1_loss_20: 0.0472 - dense_1_loss_21: 0.0469 - dense_1_loss_22: 0.0485 - dense_1_loss_23: 0.0466 - dense_1_loss_24: 0.0461 - dense_1_loss_25: 0.0479 - dense_1_loss_26: 0.0475 - dense_1_loss_27: 0.0527 - dense_1_loss_28: 0.0578 - dense_1_loss_29: 0.0604 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s - loss: 7.4189 - dense_1_loss_1: 3.8122 - dense_1_loss_2: 1.5829 - dense_1_loss_3: 0.5421 - dense_1_loss_4: 0.1855 - dense_1_loss_5: 0.1210 - dense_1_loss_6: 0.0787 - dense_1_loss_7: 0.0620 - dense_1_loss_8: 0.0604 - dense_1_loss_9: 0.0535 - dense_1_loss_10: 0.0480 - dense_1_loss_11: 0.0462 - dense_1_loss_12: 0.0436 - dense_1_loss_13: 0.0403 - dense_1_loss_14: 0.0399 - dense_1_loss_15: 0.0446 - dense_1_loss_16: 0.0423 - dense_1_loss_17: 0.0391 - dense_1_loss_18: 0.0452 - dense_1_loss_19: 0.0460 - dense_1_loss_20: 0.0457 - dense_1_loss_21: 0.0452 - dense_1_loss_22: 0.0471 - dense_1_loss_23: 0.0451 - dense_1_loss_24: 0.0446 - dense_1_loss_25: 0.0464 - dense_1_loss_26: 0.0460 - dense_1_loss_27: 0.0511 - dense_1_loss_28: 0.0558 - dense_1_loss_29: 0.0588 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s - loss: 7.3389 - dense_1_loss_1: 3.8092 - dense_1_loss_2: 1.5661 - dense_1_loss_3: 0.5311 - dense_1_loss_4: 0.1796 - dense_1_loss_5: 0.1169 - dense_1_loss_6: 0.0762 - dense_1_loss_7: 0.0601 - dense_1_loss_8: 0.0585 - dense_1_loss_9: 0.0518 - dense_1_loss_10: 0.0465 - dense_1_loss_11: 0.0447 - dense_1_loss_12: 0.0421 - dense_1_loss_13: 0.0390 - dense_1_loss_14: 0.0386 - dense_1_loss_15: 0.0432 - dense_1_loss_16: 0.0410 - dense_1_loss_17: 0.0378 - dense_1_loss_18: 0.0437 - dense_1_loss_19: 0.0443 - dense_1_loss_20: 0.0443 - dense_1_loss_21: 0.0437 - dense_1_loss_22: 0.0455 - dense_1_loss_23: 0.0433 - dense_1_loss_24: 0.0428 - dense_1_loss_25: 0.0449 - dense_1_loss_26: 0.0441 - dense_1_loss_27: 0.0494 - dense_1_loss_28: 0.0539 - dense_1_loss_29: 0.0567 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s - loss: 7.2656 - dense_1_loss_1: 3.8063 - dense_1_loss_2: 1.5500 - dense_1_loss_3: 0.5212 - dense_1_loss_4: 0.1746 - dense_1_loss_5: 0.1135 - dense_1_loss_6: 0.0740 - dense_1_loss_7: 0.0582 - dense_1_loss_8: 0.0567 - dense_1_loss_9: 0.0503 - dense_1_loss_10: 0.0450 - dense_1_loss_11: 0.0433 - dense_1_loss_12: 0.0408 - dense_1_loss_13: 0.0378 - dense_1_loss_14: 0.0375 - dense_1_loss_15: 0.0418 - dense_1_loss_16: 0.0398 - dense_1_loss_17: 0.0365 - dense_1_loss_18: 0.0423 - dense_1_loss_19: 0.0428 - dense_1_loss_20: 0.0429 - dense_1_loss_21: 0.0423 - dense_1_loss_22: 0.0440 - dense_1_loss_23: 0.0419 - dense_1_loss_24: 0.0415 - dense_1_loss_25: 0.0434 - dense_1_loss_26: 0.0428 - dense_1_loss_27: 0.0476 - dense_1_loss_28: 0.0520 - dense_1_loss_29: 0.0550 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s - loss: 7.1931 - dense_1_loss_1: 3.8032 - dense_1_loss_2: 1.5337 - dense_1_loss_3: 0.5116 - dense_1_loss_4: 0.1695 - dense_1_loss_5: 0.1096 - dense_1_loss_6: 0.0717 - dense_1_loss_7: 0.0564 - dense_1_loss_8: 0.0549 - dense_1_loss_9: 0.0487 - dense_1_loss_10: 0.0436 - dense_1_loss_11: 0.0419 - dense_1_loss_12: 0.0395 - dense_1_loss_13: 0.0365 - dense_1_loss_14: 0.0363 - dense_1_loss_15: 0.0405 - dense_1_loss_16: 0.0385 - dense_1_loss_17: 0.0354 - dense_1_loss_18: 0.0409 - dense_1_loss_19: 0.0415 - dense_1_loss_20: 0.0412 - dense_1_loss_21: 0.0410 - dense_1_loss_22: 0.0425 - dense_1_loss_23: 0.0407 - dense_1_loss_24: 0.0403 - dense_1_loss_25: 0.0420 - dense_1_loss_26: 0.0416 - dense_1_loss_27: 0.0462 - dense_1_loss_28: 0.0505 - dense_1_loss_29: 0.0534 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s - loss: 7.1229 - dense_1_loss_1: 3.8006 - dense_1_loss_2: 1.5186 - dense_1_loss_3: 0.5005 - dense_1_loss_4: 0.1645 - dense_1_loss_5: 0.1059 - dense_1_loss_6: 0.0696 - dense_1_loss_7: 0.0547 - dense_1_loss_8: 0.0533 - dense_1_loss_9: 0.0470 - dense_1_loss_10: 0.0423 - dense_1_loss_11: 0.0405 - dense_1_loss_12: 0.0383 - dense_1_loss_13: 0.0353 - dense_1_loss_14: 0.0351 - dense_1_loss_15: 0.0394 - dense_1_loss_16: 0.0373 - dense_1_loss_17: 0.0343 - dense_1_loss_18: 0.0397 - dense_1_loss_19: 0.0403 - dense_1_loss_20: 0.0399 - dense_1_loss_21: 0.0398 - dense_1_loss_22: 0.0412 - dense_1_loss_23: 0.0396 - dense_1_loss_24: 0.0390 - dense_1_loss_25: 0.0408 - dense_1_loss_26: 0.0402 - dense_1_loss_27: 0.0447 - dense_1_loss_28: 0.0489 - dense_1_loss_29: 0.0517 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s - loss: 7.0565 - dense_1_loss_1: 3.7976 - dense_1_loss_2: 1.5031 - dense_1_loss_3: 0.4916 - dense_1_loss_4: 0.1600 - dense_1_loss_5: 0.1030 - dense_1_loss_6: 0.0676 - dense_1_loss_7: 0.0531 - dense_1_loss_8: 0.0518 - dense_1_loss_9: 0.0457 - dense_1_loss_10: 0.0410 - dense_1_loss_11: 0.0393 - dense_1_loss_12: 0.0372 - dense_1_loss_13: 0.0344 - dense_1_loss_14: 0.0341 - dense_1_loss_15: 0.0383 - dense_1_loss_16: 0.0362 - dense_1_loss_17: 0.0332 - dense_1_loss_18: 0.0385 - dense_1_loss_19: 0.0390 - dense_1_loss_20: 0.0386 - dense_1_loss_21: 0.0385 - dense_1_loss_22: 0.0400 - dense_1_loss_23: 0.0384 - dense_1_loss_24: 0.0378 - dense_1_loss_25: 0.0396 - dense_1_loss_26: 0.0387 - dense_1_loss_27: 0.0433 - dense_1_loss_28: 0.0472 - dense_1_loss_29: 0.0499 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 6.9931 - dense_1_loss_1: 3.7948 - dense_1_loss_2: 1.4882 - dense_1_loss_3: 0.4822 - dense_1_loss_4: 0.1555 - dense_1_loss_5: 0.0998 - dense_1_loss_6: 0.0657 - dense_1_loss_7: 0.0516 - dense_1_loss_8: 0.0503 - dense_1_loss_9: 0.0444 - dense_1_loss_10: 0.0398 - dense_1_loss_11: 0.0382 - dense_1_loss_12: 0.0361 - dense_1_loss_13: 0.0333 - dense_1_loss_14: 0.0332 - dense_1_loss_15: 0.0370 - dense_1_loss_16: 0.0351 - dense_1_loss_17: 0.0322 - dense_1_loss_18: 0.0374 - dense_1_loss_19: 0.0377 - dense_1_loss_20: 0.0374 - dense_1_loss_21: 0.0374 - dense_1_loss_22: 0.0389 - dense_1_loss_23: 0.0372 - dense_1_loss_24: 0.0367 - dense_1_loss_25: 0.0385 - dense_1_loss_26: 0.0376 - dense_1_loss_27: 0.0422 - dense_1_loss_28: 0.0460 - dense_1_loss_29: 0.0486 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s - loss: 6.9335 - dense_1_loss_1: 3.7920 - dense_1_loss_2: 1.4742 - dense_1_loss_3: 0.4735 - dense_1_loss_4: 0.1516 - dense_1_loss_5: 0.0973 - dense_1_loss_6: 0.0640 - dense_1_loss_7: 0.0502 - dense_1_loss_8: 0.0489 - dense_1_loss_9: 0.0432 - dense_1_loss_10: 0.0386 - dense_1_loss_11: 0.0371 - dense_1_loss_12: 0.0351 - dense_1_loss_13: 0.0323 - dense_1_loss_14: 0.0323 - dense_1_loss_15: 0.0360 - dense_1_loss_16: 0.0342 - dense_1_loss_17: 0.0313 - dense_1_loss_18: 0.0364 - dense_1_loss_19: 0.0365 - dense_1_loss_20: 0.0364 - dense_1_loss_21: 0.0362 - dense_1_loss_22: 0.0379 - dense_1_loss_23: 0.0360 - dense_1_loss_24: 0.0355 - dense_1_loss_25: 0.0373 - dense_1_loss_26: 0.0363 - dense_1_loss_27: 0.0412 - dense_1_loss_28: 0.0448 - dense_1_loss_29: 0.0472 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s - loss: 6.8727 - dense_1_loss_1: 3.7892 - dense_1_loss_2: 1.4589 - dense_1_loss_3: 0.4648 - dense_1_loss_4: 0.1471 - dense_1_loss_5: 0.0946 - dense_1_loss_6: 0.0622 - dense_1_loss_7: 0.0487 - dense_1_loss_8: 0.0473 - dense_1_loss_9: 0.0420 - dense_1_loss_10: 0.0374 - dense_1_loss_11: 0.0361 - dense_1_loss_12: 0.0342 - dense_1_loss_13: 0.0313 - dense_1_loss_14: 0.0315 - dense_1_loss_15: 0.0350 - dense_1_loss_16: 0.0333 - dense_1_loss_17: 0.0304 - dense_1_loss_18: 0.0354 - dense_1_loss_19: 0.0354 - dense_1_loss_20: 0.0355 - dense_1_loss_21: 0.0351 - dense_1_loss_22: 0.0368 - dense_1_loss_23: 0.0350 - dense_1_loss_24: 0.0346 - dense_1_loss_25: 0.0361 - dense_1_loss_26: 0.0354 - dense_1_loss_27: 0.0400 - dense_1_loss_28: 0.0436 - dense_1_loss_29: 0.0458 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s - loss: 6.8170 - dense_1_loss_1: 3.7865 - dense_1_loss_2: 1.4448 - dense_1_loss_3: 0.4568 - dense_1_loss_4: 0.1436 - dense_1_loss_5: 0.0921 - dense_1_loss_6: 0.0605 - dense_1_loss_7: 0.0474 - dense_1_loss_8: 0.0461 - dense_1_loss_9: 0.0409 - dense_1_loss_10: 0.0364 - dense_1_loss_11: 0.0351 - dense_1_loss_12: 0.0333 - dense_1_loss_13: 0.0304 - dense_1_loss_14: 0.0305 - dense_1_loss_15: 0.0341 - dense_1_loss_16: 0.0323 - dense_1_loss_17: 0.0296 - dense_1_loss_18: 0.0344 - dense_1_loss_19: 0.0345 - dense_1_loss_20: 0.0343 - dense_1_loss_21: 0.0341 - dense_1_loss_22: 0.0358 - dense_1_loss_23: 0.0342 - dense_1_loss_24: 0.0337 - dense_1_loss_25: 0.0351 - dense_1_loss_26: 0.0345 - dense_1_loss_27: 0.0389 - dense_1_loss_28: 0.0424 - dense_1_loss_29: 0.0447 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s - loss: 6.7626 - dense_1_loss_1: 3.7837 - dense_1_loss_2: 1.4318 - dense_1_loss_3: 0.4481 - dense_1_loss_4: 0.1400 - dense_1_loss_5: 0.0896 - dense_1_loss_6: 0.0589 - dense_1_loss_7: 0.0462 - dense_1_loss_8: 0.0449 - dense_1_loss_9: 0.0398 - dense_1_loss_10: 0.0354 - dense_1_loss_11: 0.0342 - dense_1_loss_12: 0.0324 - dense_1_loss_13: 0.0296 - dense_1_loss_14: 0.0296 - dense_1_loss_15: 0.0332 - dense_1_loss_16: 0.0315 - dense_1_loss_17: 0.0288 - dense_1_loss_18: 0.0335 - dense_1_loss_19: 0.0336 - dense_1_loss_20: 0.0333 - dense_1_loss_21: 0.0332 - dense_1_loss_22: 0.0348 - dense_1_loss_23: 0.0333 - dense_1_loss_24: 0.0328 - dense_1_loss_25: 0.0342 - dense_1_loss_26: 0.0337 - dense_1_loss_27: 0.0378 - dense_1_loss_28: 0.0413 - dense_1_loss_29: 0.0436 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s - loss: 6.7109 - dense_1_loss_1: 3.7812 - dense_1_loss_2: 1.4182 - dense_1_loss_3: 0.4404 - dense_1_loss_4: 0.1366 - dense_1_loss_5: 0.0875 - dense_1_loss_6: 0.0575 - dense_1_loss_7: 0.0449 - dense_1_loss_8: 0.0438 - dense_1_loss_9: 0.0387 - dense_1_loss_10: 0.0345 - dense_1_loss_11: 0.0333 - dense_1_loss_12: 0.0316 - dense_1_loss_13: 0.0289 - dense_1_loss_14: 0.0288 - dense_1_loss_15: 0.0324 - dense_1_loss_16: 0.0307 - dense_1_loss_17: 0.0280 - dense_1_loss_18: 0.0326 - dense_1_loss_19: 0.0327 - dense_1_loss_20: 0.0324 - dense_1_loss_21: 0.0323 - dense_1_loss_22: 0.0339 - dense_1_loss_23: 0.0324 - dense_1_loss_24: 0.0320 - dense_1_loss_25: 0.0333 - dense_1_loss_26: 0.0328 - dense_1_loss_27: 0.0367 - dense_1_loss_28: 0.0401 - dense_1_loss_29: 0.0425 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s - loss: 6.6614 - dense_1_loss_1: 3.7782 - dense_1_loss_2: 1.4059 - dense_1_loss_3: 0.4330 - dense_1_loss_4: 0.1335 - dense_1_loss_5: 0.0855 - dense_1_loss_6: 0.0561 - dense_1_loss_7: 0.0439 - dense_1_loss_8: 0.0428 - dense_1_loss_9: 0.0378 - dense_1_loss_10: 0.0337 - dense_1_loss_11: 0.0324 - dense_1_loss_12: 0.0307 - dense_1_loss_13: 0.0282 - dense_1_loss_14: 0.0280 - dense_1_loss_15: 0.0316 - dense_1_loss_16: 0.0299 - dense_1_loss_17: 0.0274 - dense_1_loss_18: 0.0317 - dense_1_loss_19: 0.0318 - dense_1_loss_20: 0.0316 - dense_1_loss_21: 0.0315 - dense_1_loss_22: 0.0330 - dense_1_loss_23: 0.0315 - dense_1_loss_24: 0.0311 - dense_1_loss_25: 0.0325 - dense_1_loss_26: 0.0319 - dense_1_loss_27: 0.0357 - dense_1_loss_28: 0.0390 - dense_1_loss_29: 0.0415 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s - loss: 6.6118 - dense_1_loss_1: 3.7755 - dense_1_loss_2: 1.3929 - dense_1_loss_3: 0.4252 - dense_1_loss_4: 0.1304 - dense_1_loss_5: 0.0834 - dense_1_loss_6: 0.0548 - dense_1_loss_7: 0.0427 - dense_1_loss_8: 0.0417 - dense_1_loss_9: 0.0369 - dense_1_loss_10: 0.0328 - dense_1_loss_11: 0.0317 - dense_1_loss_12: 0.0300 - dense_1_loss_13: 0.0275 - dense_1_loss_14: 0.0274 - dense_1_loss_15: 0.0308 - dense_1_loss_16: 0.0292 - dense_1_loss_17: 0.0267 - dense_1_loss_18: 0.0309 - dense_1_loss_19: 0.0308 - dense_1_loss_20: 0.0309 - dense_1_loss_21: 0.0307 - dense_1_loss_22: 0.0321 - dense_1_loss_23: 0.0306 - dense_1_loss_24: 0.0303 - dense_1_loss_25: 0.0317 - dense_1_loss_26: 0.0309 - dense_1_loss_27: 0.0349 - dense_1_loss_28: 0.0381 - dense_1_loss_29: 0.0404 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s - loss: 6.5646 - dense_1_loss_1: 3.7728 - dense_1_loss_2: 1.3800 - dense_1_loss_3: 0.4179 - dense_1_loss_4: 0.1272 - dense_1_loss_5: 0.0814 - dense_1_loss_6: 0.0534 - dense_1_loss_7: 0.0417 - dense_1_loss_8: 0.0407 - dense_1_loss_9: 0.0360 - dense_1_loss_10: 0.0320 - dense_1_loss_11: 0.0309 - dense_1_loss_12: 0.0292 - dense_1_loss_13: 0.0269 - dense_1_loss_14: 0.0268 - dense_1_loss_15: 0.0300 - dense_1_loss_16: 0.0285 - dense_1_loss_17: 0.0261 - dense_1_loss_18: 0.0302 - dense_1_loss_19: 0.0301 - dense_1_loss_20: 0.0301 - dense_1_loss_21: 0.0299 - dense_1_loss_22: 0.0314 - dense_1_loss_23: 0.0298 - dense_1_loss_24: 0.0297 - dense_1_loss_25: 0.0310 - dense_1_loss_26: 0.0302 - dense_1_loss_27: 0.0341 - dense_1_loss_28: 0.0373 - dense_1_loss_29: 0.0395 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s - loss: 6.5202 - dense_1_loss_1: 3.7702 - dense_1_loss_2: 1.3682 - dense_1_loss_3: 0.4111 - dense_1_loss_4: 0.1244 - dense_1_loss_5: 0.0797 - dense_1_loss_6: 0.0521 - dense_1_loss_7: 0.0406 - dense_1_loss_8: 0.0398 - dense_1_loss_9: 0.0351 - dense_1_loss_10: 0.0312 - dense_1_loss_11: 0.0302 - dense_1_loss_12: 0.0286 - dense_1_loss_13: 0.0262 - dense_1_loss_14: 0.0261 - dense_1_loss_15: 0.0293 - dense_1_loss_16: 0.0278 - dense_1_loss_17: 0.0254 - dense_1_loss_18: 0.0295 - dense_1_loss_19: 0.0294 - dense_1_loss_20: 0.0293 - dense_1_loss_21: 0.0292 - dense_1_loss_22: 0.0307 - dense_1_loss_23: 0.0292 - dense_1_loss_24: 0.0290 - dense_1_loss_25: 0.0302 - dense_1_loss_26: 0.0294 - dense_1_loss_27: 0.0334 - dense_1_loss_28: 0.0366 - dense_1_loss_29: 0.0384 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 6.4768 - dense_1_loss_1: 3.7678 - dense_1_loss_2: 1.3562 - dense_1_loss_3: 0.4045 - dense_1_loss_4: 0.1218 - dense_1_loss_5: 0.0779 - dense_1_loss_6: 0.0509 - dense_1_loss_7: 0.0397 - dense_1_loss_8: 0.0389 - dense_1_loss_9: 0.0343 - dense_1_loss_10: 0.0305 - dense_1_loss_11: 0.0295 - dense_1_loss_12: 0.0279 - dense_1_loss_13: 0.0256 - dense_1_loss_14: 0.0255 - dense_1_loss_15: 0.0287 - dense_1_loss_16: 0.0272 - dense_1_loss_17: 0.0248 - dense_1_loss_18: 0.0287 - dense_1_loss_19: 0.0287 - dense_1_loss_20: 0.0287 - dense_1_loss_21: 0.0284 - dense_1_loss_22: 0.0300 - dense_1_loss_23: 0.0285 - dense_1_loss_24: 0.0283 - dense_1_loss_25: 0.0295 - dense_1_loss_26: 0.0287 - dense_1_loss_27: 0.0325 - dense_1_loss_28: 0.0357 - dense_1_loss_29: 0.0375 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s - loss: 6.4333 - dense_1_loss_1: 3.7650 - dense_1_loss_2: 1.3444 - dense_1_loss_3: 0.3976 - dense_1_loss_4: 0.1190 - dense_1_loss_5: 0.0762 - dense_1_loss_6: 0.0498 - dense_1_loss_7: 0.0388 - dense_1_loss_8: 0.0381 - dense_1_loss_9: 0.0335 - dense_1_loss_10: 0.0298 - dense_1_loss_11: 0.0288 - dense_1_loss_12: 0.0272 - dense_1_loss_13: 0.0250 - dense_1_loss_14: 0.0249 - dense_1_loss_15: 0.0280 - dense_1_loss_16: 0.0266 - dense_1_loss_17: 0.0242 - dense_1_loss_18: 0.0281 - dense_1_loss_19: 0.0280 - dense_1_loss_20: 0.0280 - dense_1_loss_21: 0.0278 - dense_1_loss_22: 0.0293 - dense_1_loss_23: 0.0279 - dense_1_loss_24: 0.0276 - dense_1_loss_25: 0.0288 - dense_1_loss_26: 0.0281 - dense_1_loss_27: 0.0317 - dense_1_loss_28: 0.0347 - dense_1_loss_29: 0.0366 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s - loss: 6.3930 - dense_1_loss_1: 3.7622 - dense_1_loss_2: 1.3332 - dense_1_loss_3: 0.3912 - dense_1_loss_4: 0.1166 - dense_1_loss_5: 0.0747 - dense_1_loss_6: 0.0487 - dense_1_loss_7: 0.0380 - dense_1_loss_8: 0.0373 - dense_1_loss_9: 0.0327 - dense_1_loss_10: 0.0291 - dense_1_loss_11: 0.0282 - dense_1_loss_12: 0.0266 - dense_1_loss_13: 0.0244 - dense_1_loss_14: 0.0244 - dense_1_loss_15: 0.0274 - dense_1_loss_16: 0.0260 - dense_1_loss_17: 0.0237 - dense_1_loss_18: 0.0274 - dense_1_loss_19: 0.0274 - dense_1_loss_20: 0.0273 - dense_1_loss_21: 0.0271 - dense_1_loss_22: 0.0287 - dense_1_loss_23: 0.0272 - dense_1_loss_24: 0.0270 - dense_1_loss_25: 0.0281 - dense_1_loss_26: 0.0274 - dense_1_loss_27: 0.0310 - dense_1_loss_28: 0.0339 - dense_1_loss_29: 0.0358 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s - loss: 6.3535 - dense_1_loss_1: 3.7600 - dense_1_loss_2: 1.3218 - dense_1_loss_3: 0.3844 - dense_1_loss_4: 0.1144 - dense_1_loss_5: 0.0731 - dense_1_loss_6: 0.0477 - dense_1_loss_7: 0.0373 - dense_1_loss_8: 0.0365 - dense_1_loss_9: 0.0320 - dense_1_loss_10: 0.0286 - dense_1_loss_11: 0.0276 - dense_1_loss_12: 0.0261 - dense_1_loss_13: 0.0239 - dense_1_loss_14: 0.0239 - dense_1_loss_15: 0.0268 - dense_1_loss_16: 0.0255 - dense_1_loss_17: 0.0232 - dense_1_loss_18: 0.0268 - dense_1_loss_19: 0.0268 - dense_1_loss_20: 0.0267 - dense_1_loss_21: 0.0266 - dense_1_loss_22: 0.0280 - dense_1_loss_23: 0.0266 - dense_1_loss_24: 0.0264 - dense_1_loss_25: 0.0275 - dense_1_loss_26: 0.0268 - dense_1_loss_27: 0.0304 - dense_1_loss_28: 0.0331 - dense_1_loss_29: 0.0350 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s - loss: 6.3148 - dense_1_loss_1: 3.7572 - dense_1_loss_2: 1.3110 - dense_1_loss_3: 0.3777 - dense_1_loss_4: 0.1121 - dense_1_loss_5: 0.0716 - dense_1_loss_6: 0.0466 - dense_1_loss_7: 0.0366 - dense_1_loss_8: 0.0358 - dense_1_loss_9: 0.0314 - dense_1_loss_10: 0.0279 - dense_1_loss_11: 0.0270 - dense_1_loss_12: 0.0255 - dense_1_loss_13: 0.0234 - dense_1_loss_14: 0.0234 - dense_1_loss_15: 0.0262 - dense_1_loss_16: 0.0250 - dense_1_loss_17: 0.0227 - dense_1_loss_18: 0.0262 - dense_1_loss_19: 0.0262 - dense_1_loss_20: 0.0261 - dense_1_loss_21: 0.0260 - dense_1_loss_22: 0.0274 - dense_1_loss_23: 0.0259 - dense_1_loss_24: 0.0259 - dense_1_loss_25: 0.0270 - dense_1_loss_26: 0.0262 - dense_1_loss_27: 0.0298 - dense_1_loss_28: 0.0325 - dense_1_loss_29: 0.0343 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s - loss: 6.2770 - dense_1_loss_1: 3.7546 - dense_1_loss_2: 1.2998 - dense_1_loss_3: 0.3718 - dense_1_loss_4: 0.1100 - dense_1_loss_5: 0.0703 - dense_1_loss_6: 0.0457 - dense_1_loss_7: 0.0357 - dense_1_loss_8: 0.0350 - dense_1_loss_9: 0.0308 - dense_1_loss_10: 0.0273 - dense_1_loss_11: 0.0265 - dense_1_loss_12: 0.0250 - dense_1_loss_13: 0.0229 - dense_1_loss_14: 0.0228 - dense_1_loss_15: 0.0257 - dense_1_loss_16: 0.0245 - dense_1_loss_17: 0.0222 - dense_1_loss_18: 0.0257 - dense_1_loss_19: 0.0257 - dense_1_loss_20: 0.0255 - dense_1_loss_21: 0.0254 - dense_1_loss_22: 0.0268 - dense_1_loss_23: 0.0254 - dense_1_loss_24: 0.0253 - dense_1_loss_25: 0.0264 - dense_1_loss_26: 0.0255 - dense_1_loss_27: 0.0292 - dense_1_loss_28: 0.0319 - dense_1_loss_29: 0.0335 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s - loss: 6.2401 - dense_1_loss_1: 3.7521 - dense_1_loss_2: 1.2890 - dense_1_loss_3: 0.3659 - dense_1_loss_4: 0.1079 - dense_1_loss_5: 0.0687 - dense_1_loss_6: 0.0448 - dense_1_loss_7: 0.0350 - dense_1_loss_8: 0.0343 - dense_1_loss_9: 0.0302 - dense_1_loss_10: 0.0267 - dense_1_loss_11: 0.0260 - dense_1_loss_12: 0.0244 - dense_1_loss_13: 0.0224 - dense_1_loss_14: 0.0224 - dense_1_loss_15: 0.0252 - dense_1_loss_16: 0.0240 - dense_1_loss_17: 0.0217 - dense_1_loss_18: 0.0251 - dense_1_loss_19: 0.0251 - dense_1_loss_20: 0.0249 - dense_1_loss_21: 0.0249 - dense_1_loss_22: 0.0263 - dense_1_loss_23: 0.0249 - dense_1_loss_24: 0.0248 - dense_1_loss_25: 0.0258 - dense_1_loss_26: 0.0250 - dense_1_loss_27: 0.0286 - dense_1_loss_28: 0.0312 - dense_1_loss_29: 0.0329 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s - loss: 6.2062 - dense_1_loss_1: 3.7495 - dense_1_loss_2: 1.2792 - dense_1_loss_3: 0.3606 - dense_1_loss_4: 0.1060 - dense_1_loss_5: 0.0674 - dense_1_loss_6: 0.0441 - dense_1_loss_7: 0.0342 - dense_1_loss_8: 0.0336 - dense_1_loss_9: 0.0296 - dense_1_loss_10: 0.0261 - dense_1_loss_11: 0.0255 - dense_1_loss_12: 0.0240 - dense_1_loss_13: 0.0219 - dense_1_loss_14: 0.0219 - dense_1_loss_15: 0.0247 - dense_1_loss_16: 0.0235 - dense_1_loss_17: 0.0213 - dense_1_loss_18: 0.0246 - dense_1_loss_19: 0.0246 - dense_1_loss_20: 0.0244 - dense_1_loss_21: 0.0244 - dense_1_loss_22: 0.0258 - dense_1_loss_23: 0.0244 - dense_1_loss_24: 0.0243 - dense_1_loss_25: 0.0253 - dense_1_loss_26: 0.0246 - dense_1_loss_27: 0.0279 - dense_1_loss_28: 0.0306 - dense_1_loss_29: 0.0322 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s - loss: 6.1721 - dense_1_loss_1: 3.7469 - dense_1_loss_2: 1.2688 - dense_1_loss_3: 0.3552 - dense_1_loss_4: 0.1042 - dense_1_loss_5: 0.0662 - dense_1_loss_6: 0.0432 - dense_1_loss_7: 0.0336 - dense_1_loss_8: 0.0330 - dense_1_loss_9: 0.0290 - dense_1_loss_10: 0.0256 - dense_1_loss_11: 0.0249 - dense_1_loss_12: 0.0235 - dense_1_loss_13: 0.0215 - dense_1_loss_14: 0.0214 - dense_1_loss_15: 0.0242 - dense_1_loss_16: 0.0230 - dense_1_loss_17: 0.0209 - dense_1_loss_18: 0.0241 - dense_1_loss_19: 0.0241 - dense_1_loss_20: 0.0239 - dense_1_loss_21: 0.0239 - dense_1_loss_22: 0.0253 - dense_1_loss_23: 0.0240 - dense_1_loss_24: 0.0239 - dense_1_loss_25: 0.0248 - dense_1_loss_26: 0.0241 - dense_1_loss_27: 0.0273 - dense_1_loss_28: 0.0300 - dense_1_loss_29: 0.0316 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s - loss: 6.1385 - dense_1_loss_1: 3.7445 - dense_1_loss_2: 1.2587 - dense_1_loss_3: 0.3496 - dense_1_loss_4: 0.1025 - dense_1_loss_5: 0.0650 - dense_1_loss_6: 0.0424 - dense_1_loss_7: 0.0329 - dense_1_loss_8: 0.0323 - dense_1_loss_9: 0.0285 - dense_1_loss_10: 0.0251 - dense_1_loss_11: 0.0244 - dense_1_loss_12: 0.0230 - dense_1_loss_13: 0.0211 - dense_1_loss_14: 0.0210 - dense_1_loss_15: 0.0238 - dense_1_loss_16: 0.0225 - dense_1_loss_17: 0.0205 - dense_1_loss_18: 0.0236 - dense_1_loss_19: 0.0236 - dense_1_loss_20: 0.0234 - dense_1_loss_21: 0.0234 - dense_1_loss_22: 0.0247 - dense_1_loss_23: 0.0235 - dense_1_loss_24: 0.0234 - dense_1_loss_25: 0.0243 - dense_1_loss_26: 0.0237 - dense_1_loss_27: 0.0268 - dense_1_loss_28: 0.0294 - dense_1_loss_29: 0.0310 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.9333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b5beb4240>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "The model loss will start high, (100 or so), and after 100 epochs, it should be in the single digits.  These won't be the exact number that you'll see, due to random initialization of weights.  \n",
    "For example:\n",
    "```\n",
    "Epoch 1/100\n",
    "60/60 [==============================] - 3s - loss: 125.7673\n",
    "...\n",
    "```\n",
    "Scroll to the bottom to check Epoch 100\n",
    "```\n",
    "...\n",
    "Epoch 100/100\n",
    "60/60 [==============================] - 0s - loss: 6.1861\n",
    "```\n",
    "\n",
    "Now that you have trained a model, let's go to the final section to implement an inference algorithm, and generate some music! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generating music\n",
    "\n",
    "You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. \n",
    "\n",
    "#### 3.1 - Predicting & Sampling\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "At each step of sampling, you will:\n",
    "* Take as input the activation '`a`' and cell state '`c`' from the previous state of the LSTM.\n",
    "* Forward propagate by one step.\n",
    "* Get a new output activation as well as cell state. \n",
    "* The new activation '`a`' can then be used to generate the output using the fully connected layer, `densor`. \n",
    "\n",
    "##### Initialization\n",
    "* We will initialize the following to be zeros:\n",
    "    * `x0` \n",
    "    * hidden state `a0` \n",
    "    * cell state `c0` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "* Implement the function below to sample a sequence of musical values. \n",
    "* Here are some of the key steps you'll need to implement inside the for-loop that generates the $T_y$ output characters: \n",
    "\n",
    "* Step 2.A: Use `LSTM_Cell`, which takes in the input layer, as well as the previous step's '`c`' and '`a`' to generate the current step's '`c`' and '`a`'. \n",
    "```Python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "    * Choose the appropriate variables for the input_x, hidden_state, and cell_state\n",
    "\n",
    "* Step 2.B: Compute the output by applying `densor` to compute a softmax on '`a`' to get the output for the current step. \n",
    "\n",
    "* Step 2.C: Append the output to the list `outputs`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Step 2.D: Sample x to be the one-hot version of '`out`'. \n",
    "* This allows you to pass it to the next LSTM's step.  \n",
    "* We have provided the definition of `one_hot(x)` in the 'music_utils.py' file and imported it.\n",
    "Here is the definition of `one_hot`\n",
    "```Python\n",
    "def one_hot(x):\n",
    "    x = K.argmax(x)\n",
    "    x = tf.one_hot(indices=x, depth=78) \n",
    "    x = RepeatVector(1)(x)\n",
    "    return x\n",
    "```\n",
    "Here is what the `one_hot` function is doing:\n",
    "* argmax: within the vector `x`, find the position with the maximum value and return the index of that position.  \n",
    "    * For example: argmax of [-1,0,1] finds that 1 is the maximum value, and returns the index position, which is 2.  Read the documentation for [keras.argmax](https://www.tensorflow.org/api_docs/python/tf/keras/backend/argmax).\n",
    "* one_hot: takes a list of indices and the depth of the one-hot vector (number of categories, which is 78 in this assignment).  It converts each index into the one-hot vector representation.  For instance, if the indices is [2], and the depth is 5, then the one-hot vector returned is [0,0,1,0,0].  Check out the documentation for [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot) for more examples and explanations.\n",
    "* RepeatVector(n): This takes a vector and duplicates it `n` times.  Notice that we had it repeat 1 time.  This may seem like it's not doing anything.  If you look at the documentation for [RepeatVector](https://keras.io/layers/core/#repeatvector), you'll notice that if x is a vector with dimension (m,5) and it gets passed into `RepeatVector(1)`, then the output is (m,1,5).  In other words, it adds an additional dimension (of length 1) to the resulting vector.\n",
    "* Apply the custom one_hot encoding using the [Lambda](https://keras.io/layers/core/#lambda) layer.  You saw earlier that the Lambda layer can be used like this:\n",
    "```Python\n",
    "result = Lambda(lambda x: x + 1)(input_var)\n",
    "```\n",
    "\n",
    "If you pre-define a function, you can do the same thing:\n",
    "```Python\n",
    "def add_one(x)\n",
    "    return x + 1\n",
    "\n",
    "# use the add_one function inside of the Lambda function\n",
    "result = Lambda(add_one)(input_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Inference Model:  \n",
    "This is how to use the Keras `Model`.\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "\n",
    "\n",
    "* Choose the appropriate variables for the input tensor, hidden state, cell state, and output.\n",
    "* **Hint**: the inputs to the model are the **initial** inputs and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, number of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = dense(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: \n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        # See instructions above.\n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to define your inference model. This model is hard coded to generate 50 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the inference model\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output**\n",
    "If you scroll to the bottom of the output, you'll see:\n",
    "```\n",
    "Total params: 41,678\n",
    "Trainable params: 41,678\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize inference model\n",
    "The following code creates the zero-valued vectors you will use to initialize `x` and the LSTM state variables `a` and `c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 78))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `predict_and_sample()`. \n",
    "\n",
    "* This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. \n",
    "* In order to predict the output corresponding to this input, you will need to carry-out 3 steps:\n",
    "\n",
    "\n",
    "#### Step 1\n",
    "* Use your inference model to predict an output given your set of inputs. The output `pred` should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).\n",
    "```Python\n",
    "inference_model.predict([input_x_init, hidden_state_init, cell_state_init])\n",
    "```\n",
    "    * Choose the appropriate input arguments to `predict` from the input arguments of this `predict_and_sample` function.\n",
    " \n",
    "#### Step 2\n",
    "* Convert `pred` into a numpy array of $T_y$ indices. \n",
    "    * Each index is computed by taking the `argmax` of an element of the `pred` list. \n",
    "    * Use [numpy.argmax](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html).\n",
    "    * Set the `axis` parameter.\n",
    "        * Remember that the shape of the prediction is $(m, T_{y}, n_{values})$\n",
    "\n",
    "#### Step 3  \n",
    "* Convert the indices into their one-hot vector representations. \n",
    "    * Use [to_categorical](https://keras.io/utils/#to_categorical).\n",
    "    * Set the `num_classes` parameter. Note that for grading purposes: you'll need to either:\n",
    "        * Use a dimension from the given parameters of `predict_and_sample()` (for example, one of the dimensions of x_initializer has the value for the number of distinct classes).\n",
    "        * Or just hard code the number of distinct classes (will pass the grader as well).\n",
    "        * Note that using a global variable such as n_values will not work for grading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred,axis=-1)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (Ty, n_values)\n",
    "    results = to_categorical(indices, num_classes=78)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected (Approximate) Output**: \n",
    "\n",
    "* Your results **may likely differ** because Keras' results are not completely predictable. \n",
    "* However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above: \n",
    "    * You should very likely observe a sequence of indices that are not all identical. \n",
    "    * Moreover, you should observe that: \n",
    "        * np.argmax(results[12]) is the first element of list(indices[12:18]) \n",
    "        * and np.argmax(results[17]) is the last element of list(indices[12:18]). \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[12])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        1\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[17])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        42\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **list(indices[12:18])** =\n",
    "        </td>\n",
    "        <td>\n",
    "            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Generate music \n",
    "\n",
    "Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your `predict_and_sample()` function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). \n",
    "\n",
    "Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot of the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so let's use it in our implementation as well. \n",
    "\n",
    "Let's make some music! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate music and record it into your `out_stream`. This can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To listen to your music, click File->Open... Then go to \"output/\" and download \"my_music.midi\". Either play it on your computer with an application that can read midi files if you have one, or use one of the free online \"MIDI to mp3\" conversion tools to convert this to mp3.  \n",
    "\n",
    "As a reference, here is a 30 second audio clip we generated using this algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "You have come to the end of the notebook. \n",
    "\n",
    "\n",
    "## What you should remember\n",
    "- A sequence model can be used to generate musical values, which are then post-processed into midi music. \n",
    "- Fairly similar models can be used to generate dinosaur names or to generate music, with the major difference being the input fed to the model.  \n",
    "- In Keras, sequence generation involves defining layers with shared weights, which are then repeated for the different time steps $1, \\ldots, T_x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this assignment and generating a jazz solo! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim's GitHub repository.\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- François Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)\n",
    "\n",
    "We're also grateful to François Germain for valuable feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
